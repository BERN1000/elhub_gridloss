{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fa696c9",
   "metadata": {},
   "source": [
    "# Elhub API data - Gridloss - Summerproject 2025\n",
    "\n",
    "## Visualization\n",
    "\n",
    "Bjørn Eirik Rognskog Nordbak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f640dfd4",
   "metadata": {},
   "source": [
    "### Importing data from Elhub API\n",
    "https://api.elhub.no/energy-data-api#/grid-areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7aa1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "oslo = ZoneInfo(\"Europe/Oslo\")\n",
    "\n",
    "def fetch_window(start_dt, end_dt):\n",
    "    params = {\n",
    "        \"dataset\":   \"LOSS_PER_MGA_HOUR\",\n",
    "        \"startDate\": start_dt.isoformat(),\n",
    "        \"endDate\":   end_dt.isoformat(),\n",
    "    }\n",
    "    url = \"https://api.elhub.no/energy-data/v0/grid-areas\"\n",
    "    resp = requests.get(url, params=params)\n",
    "    obj = resp.json()\n",
    "    \n",
    "    # --- safeguard: if there's no \"data\", bail with empty DF ----\n",
    "    raw = obj.get(\"data\")\n",
    "    if raw is None:\n",
    "        print(f\"  → no 'data' for {start_dt.date()} → {end_dt.date()}, skipping\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # otherwise flatten\n",
    "    df = pd.json_normalize(\n",
    "        raw,\n",
    "        record_path=[\"attributes\", \"lossPerMgaHour\"],\n",
    "        meta=[\n",
    "            [\"attributes\", \"eic\"],\n",
    "            [\"attributes\", \"name\"],\n",
    "            [\"attributes\", \"status\"],\n",
    "        ],\n",
    "        errors=\"ignore\"\n",
    "    ).rename(columns={\n",
    "        \"attributes.eic\":    \"eic\",\n",
    "        \"attributes.name\":   \"name\",\n",
    "        \"attributes.status\": \"status\",\n",
    "    })\n",
    "    return df\n",
    "\n",
    "# loop as before\n",
    "span_start = datetime(2023,1,1,0,0, tzinfo=oslo)\n",
    "span_end   = datetime(2025,6,1,0,0, tzinfo=oslo)\n",
    "window = timedelta(days=7)\n",
    "\n",
    "all_chunks = []\n",
    "cur = span_start\n",
    "while cur < span_end:\n",
    "    nxt = min(cur + window, span_end)\n",
    "    print(f\"Fetching {cur.date()} → {nxt.date()}\")\n",
    "    dfc = fetch_window(cur, nxt)\n",
    "    all_chunks.append(dfc)\n",
    "    cur = nxt\n",
    "\n",
    "big_df = pd.concat(all_chunks, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2273fd68",
   "metadata": {},
   "source": [
    "### Save the data to a CSV file (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb47a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Save your DataFrame to CSV\n",
    "# Replace big_df with your DataFrame variable\n",
    "big_df.to_csv('big_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375ae101",
   "metadata": {},
   "source": [
    "### Read the CSV file (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1e41fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 2. Load the DataFrame back from CSV\n",
    "# This will recreate the DataFrame exactly as it was (aside from types inference)\n",
    "big_df = pd.read_csv('big_df.csv')\n",
    "\n",
    "big_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8925cd01",
   "metadata": {},
   "source": [
    "## Exploring the Elhub API gridloss data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b4fbf4",
   "metadata": {},
   "source": [
    "### Unique eic codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23338230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique EIC codes\n",
    "unique_eic_count = big_df['eic'].nunique()\n",
    "print(f\"Number of unique EIC codes: {unique_eic_count}\")\n",
    "\n",
    "# List them out\n",
    "unique_eics = big_df['eic'].unique()\n",
    "print(unique_eics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5909a043",
   "metadata": {},
   "source": [
    "### Unique names entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique name entries\n",
    "unique_name_count = big_df['name'].nunique()\n",
    "print(f\"Number of unique names: {unique_name_count}\")\n",
    "\n",
    "# List all unique names\n",
    "unique_names = big_df['name'].unique()\n",
    "print(unique_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22d7c4b",
   "metadata": {},
   "source": [
    "### Unique gridArea entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caefa98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique gridArea entries\n",
    "unique_gridarea_count = big_df['gridArea'].nunique()\n",
    "print(f\"Number of unique grid areas: {unique_gridarea_count}\")\n",
    "\n",
    "# List all unique gridArea codes\n",
    "unique_gridareas = big_df['gridArea'].unique()\n",
    "print(unique_gridareas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599e567b",
   "metadata": {},
   "source": [
    "### Unique priceArea entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a05441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique priceArea entries\n",
    "unique_pricearea_count = big_df['priceArea'].nunique()\n",
    "print(f\"Number of unique price areas: {unique_pricearea_count}\")\n",
    "\n",
    "# List all unique priceArea codes\n",
    "unique_priceareas = big_df['priceArea'].unique()\n",
    "print(unique_priceareas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e17e1ec",
   "metadata": {},
   "source": [
    "### Average hourly grid loss per price area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37aee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# ─── FONT SIZE SETTINGS ───────────────────────────────────────────────────────\n",
    "TITLE_FS        = 20   # plot title\n",
    "AXIS_TITLE_FS   = 16   # x/y axis titles\n",
    "TICK_FS         = 14   # x/y tick labels\n",
    "BAR_TEXT_FS     = 12   # number labels inside bars\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Assumes big_df is already in your notebook, with 'startTime' & 'calculatedLossQuantityKwh' etc.\n",
    "\n",
    "# 1) Parse startTime as UTC then convert to Oslo\n",
    "df = big_df.copy()\n",
    "df['startTime'] = (\n",
    "    pd.to_datetime(df['startTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "\n",
    "# 2) Determine span for title\n",
    "span_start = df['startTime'].min().date().isoformat()\n",
    "span_end   = df['startTime'].max().date().isoformat()\n",
    "\n",
    "# 3) Extract date (day)\n",
    "df['date'] = df['startTime'].dt.date.astype(str)\n",
    "\n",
    "# 4) Sum hourly losses into daily totals per priceArea\n",
    "daily_totals = (\n",
    "    df\n",
    "    .groupby(['date', 'priceArea'])['calculatedLossQuantityKwh']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 5) Compute the average of those daily totals for each priceArea\n",
    "avg_daily = (\n",
    "    daily_totals\n",
    "    .groupby('priceArea')['calculatedLossQuantityKwh']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'calculatedLossQuantityKwh':'avgDailyLossKWh'})\n",
    ")\n",
    "\n",
    "# 6) Build dynamic title\n",
    "title_text = (\n",
    "    f\"Average Daily Loss per Price Area\\n\"\n",
    "    f\"({span_start} to {span_end})\"\n",
    ")\n",
    "\n",
    "# 7) Create the bar chart\n",
    "fig = px.bar(\n",
    "    avg_daily,\n",
    "    x='priceArea',\n",
    "    y='avgDailyLossKWh',\n",
    "    color='priceArea',\n",
    "    text='avgDailyLossKWh',\n",
    "    title=title_text,\n",
    "    labels={'avgDailyLossKWh':'Avg Daily Loss (kWh)'},\n",
    "    color_discrete_sequence=px.colors.qualitative.Plotly\n",
    ")\n",
    "\n",
    "# 8) Place values inside bars in white for contrast\n",
    "fig.update_traces(\n",
    "    texttemplate='%{text:,.0f}',\n",
    "    textposition='inside',\n",
    "    textfont=dict(color='white', size=BAR_TEXT_FS),\n",
    "    cliponaxis=False\n",
    ")\n",
    "\n",
    "# 9) Style the layout, center title\n",
    "fig.update_layout(\n",
    "    title_font=dict(size=TITLE_FS),\n",
    "    title_x=0.5,\n",
    "    xaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    showlegend=False,\n",
    "    margin=dict(t=100, b=80)\n",
    ")\n",
    "\n",
    "# 10) Render\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37d198c",
   "metadata": {},
   "source": [
    "### Average monthly grid loss per price area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72650bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# ─── FONT SIZE SETTINGS ───────────────────────────────────────────────────────\n",
    "TITLE_FS        = 20   # plot title\n",
    "AXIS_TITLE_FS   = 16   # x/y axis titles\n",
    "TICK_FS         = 14   # x/y tick labels\n",
    "BAR_TEXT_FS     = 14   # number labels inside bars\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# assume big_df is already in your notebook, with 'startTime' & 'endTime' columns\n",
    "\n",
    "# 1) Parse start/end timestamps as UTC, convert to Oslo time\n",
    "df = big_df.copy()\n",
    "df['startTime'] = pd.to_datetime(df['startTime'], utc=True).dt.tz_convert('Europe/Oslo')\n",
    "df['endTime']   = pd.to_datetime(df['endTime'],   utc=True).dt.tz_convert('Europe/Oslo')\n",
    "\n",
    "# 2) Compute overall span for title\n",
    "span_start = df['startTime'].min().strftime('%Y-%m-%d')\n",
    "span_end   = df['endTime'].max().strftime('%Y-%m-%d')\n",
    "\n",
    "# 3) Extract month for aggregation\n",
    "df['month'] = df['startTime'].dt.to_period('M').astype(str)\n",
    "\n",
    "# 4) Sum hourly losses → monthly totals, then average per priceArea\n",
    "monthly_totals = (\n",
    "    df\n",
    "    .groupby(['month', 'priceArea'])['calculatedLossQuantityKwh']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "avg_monthly = (\n",
    "    monthly_totals\n",
    "    .groupby('priceArea')['calculatedLossQuantityKwh']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'calculatedLossQuantityKwh':'avgMonthlyLossKWh'})\n",
    ")\n",
    "\n",
    "# 5) Build title string including dynamic dates\n",
    "title_text = (\n",
    "    f\"Average Monthly Loss per Price Area\\n\"\n",
    "    f\"({span_start} to {span_end})\"\n",
    ")\n",
    "\n",
    "# 6) Create the bar chart\n",
    "fig = px.bar(\n",
    "    avg_monthly,\n",
    "    x='priceArea',\n",
    "    y='avgMonthlyLossKWh',\n",
    "    color='priceArea',\n",
    "    text='avgMonthlyLossKWh',\n",
    "    title=title_text,\n",
    "    labels={'avgMonthlyLossKWh':'Avg Monthly Loss (kWh)'},\n",
    "    color_discrete_sequence=px.colors.qualitative.Plotly\n",
    ")\n",
    "\n",
    "# 7) Move labels inside bars, white for contrast\n",
    "fig.update_traces(\n",
    "    texttemplate='%{text:,.0f}',\n",
    "    textposition='inside',\n",
    "    textfont=dict(color='white', size=BAR_TEXT_FS),\n",
    "    cliponaxis=False\n",
    ")\n",
    "\n",
    "# 8) Add padding & center title\n",
    "fig.update_layout(\n",
    "    title_font=dict(size=TITLE_FS),\n",
    "    title_x=0.5,  # center the main title\n",
    "    xaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    showlegend=False,\n",
    "    margin=dict(t=100, b=80)\n",
    ")\n",
    "\n",
    "# 9) Show\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05facf98",
   "metadata": {},
   "source": [
    "### Diurnal Profile of Grid Loss: Summer vs Winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3197a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# ───── ASSUMES big_df EXISTS WITH 'startTime', 'endTime' & 'calculatedLossQuantityKwh' ─────\n",
    "\n",
    "# 1) Parse full start/end timestamps as UTC → Oslo\n",
    "df = big_df.copy()\n",
    "df['startTime'] = pd.to_datetime(df['startTime'], utc=True).dt.tz_convert('Europe/Oslo')\n",
    "df['endTime']   = pd.to_datetime(df['endTime'],   utc=True).dt.tz_convert('Europe/Oslo')\n",
    "\n",
    "# 2) Compute the overall span for the title\n",
    "span_start = df['startTime'].min().strftime('%Y-%m-%d %H:%M')\n",
    "span_end   = df['endTime'].max().strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "# 3) Extract hour/month and label seasons\n",
    "df['hour']   = df['startTime'].dt.hour\n",
    "df['month']  = df['startTime'].dt.month\n",
    "df['season'] = df['month'].apply(lambda m: 'Summer' if m in (6,7,8)\n",
    "                                          else 'Winter' if m in (12,1,2)\n",
    "                                          else None)\n",
    "df = df[df['season'].notna()]\n",
    "\n",
    "# 4) Compute diurnal averages\n",
    "diurnal = (\n",
    "    df.groupby(['season','hour'])['calculatedLossQuantityKwh']\n",
    "      .mean()\n",
    "      .reset_index(name='avgLossKWh')\n",
    ")\n",
    "\n",
    "# 5) Build dynamic title\n",
    "title_text = (\n",
    "    f\"Diurnal Profile of Grid Loss: Summer vs Winter\\n\"\n",
    "    f\"({span_start} to {span_end} Local Time)\"\n",
    ")\n",
    "\n",
    "# 6) Plot with Plotly\n",
    "fig = px.line(\n",
    "    diurnal,\n",
    "    x='hour',\n",
    "    y='avgLossKWh',\n",
    "    color='season',\n",
    "    markers=True,\n",
    "    title=title_text,\n",
    "    labels={'hour':'Hour of Day','avgLossKWh':'Avg Loss (kWh)','season':'Season'}\n",
    ")\n",
    "\n",
    "# 7) Style\n",
    "fig.update_traces(line=dict(width=3))\n",
    "fig.update_layout(\n",
    "    title_x=0.5,\n",
    "    title_font_size=20,\n",
    "    legend_title_font_size=14,\n",
    "    legend_font_size=12,\n",
    "    xaxis=dict(tickmode='array', tickvals=list(range(24)),\n",
    "               ticktext=[str(h) for h in range(24)],\n",
    "               title_font_size=16, tickfont_size=12),\n",
    "    yaxis=dict(title_font_size=16, tickfont_size=12),\n",
    "    margin=dict(t=100, b=50, l=50, r=50)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb0ed3c",
   "metadata": {},
   "source": [
    "### Average daily net infeed in kwh per price area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42908799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# ─── FONT SIZE SETTINGS ───────────────────────────────────────────────────────\n",
    "TITLE_FS        = 20   # plot title\n",
    "AXIS_TITLE_FS   = 16   # x/y axis titles\n",
    "TICK_FS         = 14   # x/y tick labels\n",
    "BAR_TEXT_FS     = 12   # number labels inside bars\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Assumes big_df is already in your notebook, with 'startTime' & 'netInfeedQuantityKwh' columns\n",
    "\n",
    "# 1) Parse startTime as UTC then convert to Oslo\n",
    "df = big_df.copy()\n",
    "df['startTime'] = (\n",
    "    pd.to_datetime(df['startTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "\n",
    "# 2) Determine span for title\n",
    "span_start = df['startTime'].min().date().isoformat()\n",
    "span_end   = df['startTime'].max().date().isoformat()\n",
    "\n",
    "# 3) Extract date (day)\n",
    "df['date'] = df['startTime'].dt.date.astype(str)\n",
    "\n",
    "# 4) Sum hourly infeed into daily totals per priceArea\n",
    "daily_totals = (\n",
    "    df\n",
    "    .groupby(['date', 'priceArea'])['netInfeedQuantityKwh']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 5) Compute the average of those daily totals for each priceArea\n",
    "avg_daily_infeed = (\n",
    "    daily_totals\n",
    "    .groupby('priceArea')['netInfeedQuantityKwh']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'netInfeedQuantityKwh':'avgDailyInfeedKWh'})\n",
    ")\n",
    "\n",
    "# 6) Build dynamic title\n",
    "title_text = (\n",
    "    f\"Average Daily Net Infeed per Price Area\\n\"\n",
    "    f\"({span_start} to {span_end})\"\n",
    ")\n",
    "\n",
    "# 7) Create the bar chart\n",
    "fig = px.bar(\n",
    "    avg_daily_infeed,\n",
    "    x='priceArea',\n",
    "    y='avgDailyInfeedKWh',\n",
    "    color='priceArea',\n",
    "    text='avgDailyInfeedKWh',\n",
    "    title=title_text,\n",
    "    labels={'avgDailyInfeedKWh':'Avg Daily Net Infeed (kWh)'},\n",
    "    color_discrete_sequence=px.colors.qualitative.Plotly\n",
    ")\n",
    "\n",
    "# 8) Place values inside bars in white for contrast\n",
    "fig.update_traces(\n",
    "    texttemplate='%{text:,.0f}',\n",
    "    textposition='inside',\n",
    "    textfont=dict(color='white', size=BAR_TEXT_FS),\n",
    "    cliponaxis=False\n",
    ")\n",
    "\n",
    "# 9) Style the layout, center title\n",
    "fig.update_layout(\n",
    "    title_font=dict(size=TITLE_FS),\n",
    "    title_x=0.5,\n",
    "    xaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    showlegend=False,\n",
    "    margin=dict(t=100, b=80)\n",
    ")\n",
    "\n",
    "# 10) Render\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45933d8a",
   "metadata": {},
   "source": [
    "### Average monthly net infeed in kwh per price area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf3496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# ─── FONT SIZE SETTINGS ───────────────────────────────────────────────────────\n",
    "TITLE_FS        = 20   # plot title\n",
    "AXIS_TITLE_FS   = 16   # x/y axis titles\n",
    "TICK_FS         = 14   # x/y tick labels\n",
    "BAR_TEXT_FS     = 12   # number labels inside bars\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Assumes big_df is already in your notebook, with at least:\n",
    "#   'startTime', 'endTime', 'priceArea', and 'netInfeedQuantityKwh'\n",
    "\n",
    "# 1) Normalize your timestamps to Oslo local time\n",
    "df = big_df.copy()\n",
    "df['startTime'] = (\n",
    "    pd.to_datetime(df['startTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "df['endTime'] = (\n",
    "    pd.to_datetime(df['endTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "\n",
    "# 2) Compute span for the title\n",
    "span_start = df['startTime'].min().strftime('%Y-%m')\n",
    "span_end   = df['endTime'].max().strftime('%Y-%m')\n",
    "\n",
    "# 3) Extract a YYYY-MM period column for grouping\n",
    "df['month'] = df['startTime'].dt.to_period('M').astype(str)\n",
    "\n",
    "# 4) Sum hourly infeed into monthly totals per priceArea\n",
    "monthly_totals = (\n",
    "    df\n",
    "    .groupby(['month','priceArea'])['netInfeedQuantityKwh']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 5) Compute the average of those monthly totals for each priceArea\n",
    "avg_monthly = (\n",
    "    monthly_totals\n",
    "    .groupby('priceArea')['netInfeedQuantityKwh']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'netInfeedQuantityKwh':'avgMonthlyInfeedKWh'})\n",
    ")\n",
    "\n",
    "# 6) Build a dynamic title\n",
    "title_text = (\n",
    "    f\"Average Monthly Net Infeed per Price Area\\n\"\n",
    "    f\"({span_start} to {span_end})\"\n",
    ")\n",
    "\n",
    "# 7) Create the bar chart\n",
    "fig = px.bar(\n",
    "    avg_monthly,\n",
    "    x='priceArea',\n",
    "    y='avgMonthlyInfeedKWh',\n",
    "    color='priceArea',\n",
    "    text='avgMonthlyInfeedKWh',\n",
    "    title=title_text,\n",
    "    labels={'avgMonthlyInfeedKWh':'Avg Monthly Net Infeed (kWh)'},\n",
    "    color_discrete_sequence=px.colors.qualitative.Plotly\n",
    ")\n",
    "\n",
    "# 8) Place values inside bars, white for contrast\n",
    "fig.update_traces(\n",
    "    texttemplate='%{text:,.0f}',\n",
    "    textposition='inside',\n",
    "    textfont=dict(color='white', size=BAR_TEXT_FS),\n",
    "    cliponaxis=False\n",
    ")\n",
    "\n",
    "# 9) Style & center title\n",
    "fig.update_layout(\n",
    "    title_font=dict(size=TITLE_FS),\n",
    "    title_x=0.5,\n",
    "    xaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    showlegend=False,\n",
    "    margin=dict(t=100, b=80)\n",
    ")\n",
    "\n",
    "# 10) Render\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8b9280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# ───── ASSUMES big_df EXISTS WITH 'startTime', 'endTime' & 'netInfeedQuantityKwh' ─────\n",
    "\n",
    "# 1) Parse full start/end timestamps as UTC → Oslo\n",
    "df = big_df.copy()\n",
    "df['startTime'] = pd.to_datetime(df['startTime'], utc=True).dt.tz_convert('Europe/Oslo')\n",
    "df['endTime']   = pd.to_datetime(df['endTime'],   utc=True).dt.tz_convert('Europe/Oslo')\n",
    "\n",
    "# 2) Compute the overall span for the title\n",
    "span_start = df['startTime'].min().strftime('%Y-%m-%d %H:%M')\n",
    "span_end   = df['endTime'].max().strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "# 3) Extract hour/month and label seasons\n",
    "df['hour']   = df['startTime'].dt.hour\n",
    "df['month']  = df['startTime'].dt.month\n",
    "df['season'] = df['month'].apply(\n",
    "    lambda m: 'Summer' if m in (6,7,8)\n",
    "              else 'Winter' if m in (12,1,2)\n",
    "              else None\n",
    ")\n",
    "df = df[df['season'].notna()]\n",
    "\n",
    "# 4) Compute diurnal averages of net infeed\n",
    "diurnal_infeed = (\n",
    "    df\n",
    "    .groupby(['season','hour'])['netInfeedQuantityKwh']\n",
    "    .mean()\n",
    "    .reset_index(name='avgInfeedKWh')\n",
    ")\n",
    "\n",
    "# 5) Build dynamic title\n",
    "title_text = (\n",
    "    f\"Diurnal Profile of Net Infeed: Summer vs Winter\\n\"\n",
    "    f\"({span_start} to {span_end} Local Time)\"\n",
    ")\n",
    "\n",
    "# 6) Plot with Plotly\n",
    "fig = px.line(\n",
    "    diurnal_infeed,\n",
    "    x='hour',\n",
    "    y='avgInfeedKWh',\n",
    "    color='season',\n",
    "    markers=True,\n",
    "    title=title_text,\n",
    "    labels={\n",
    "        'hour': 'Hour of Day',\n",
    "        'avgInfeedKWh': 'Avg Net Infeed (kWh)',\n",
    "        'season': 'Season'\n",
    "    }\n",
    ")\n",
    "\n",
    "# 7) Style\n",
    "fig.update_traces(line=dict(width=3))\n",
    "fig.update_layout(\n",
    "    title_x=0.5,\n",
    "    title_font_size=20,\n",
    "    legend_title_font_size=14,\n",
    "    legend_font_size=12,\n",
    "    xaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=list(range(24)),\n",
    "        ticktext=[str(h) for h in range(24)],\n",
    "        title_font_size=16,\n",
    "        tickfont_size=12\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_font_size=16,\n",
    "        tickfont_size=12\n",
    "    ),\n",
    "    margin=dict(t=100, b=50, l=50, r=50)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18499281",
   "metadata": {},
   "source": [
    "### Daily Grid Loss by Price Area (displaying every day, not aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfb36e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# 1) Prepare your DataFrame (assumes big_df is loaded)\n",
    "df = big_df.copy()\n",
    "df['startTime'] = pd.to_datetime(df['startTime'], utc=True).dt.tz_convert('Europe/Oslo')\n",
    "\n",
    "# 2) Extract date (YYYY-MM-DD)\n",
    "df['date'] = df['startTime'].dt.date.astype(str)\n",
    "\n",
    "# 3) Aggregate total loss per day and priceArea\n",
    "daily_loss = (\n",
    "    df\n",
    "    .groupby(['date', 'priceArea'])['calculatedLossQuantityKwh']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 4) Create a stacked bar chart for daily loss\n",
    "fig = px.bar(\n",
    "    daily_loss,\n",
    "    x='date',\n",
    "    y='calculatedLossQuantityKwh',\n",
    "    color='priceArea',\n",
    "    title='Daily Grid Loss by Price Area (stacked)',\n",
    "    labels={\n",
    "        'date': 'Date',\n",
    "        'calculatedLossQuantityKwh': 'Total Loss (kWh)',\n",
    "        'priceArea': 'Price Area'\n",
    "    }\n",
    ")\n",
    "\n",
    "# 5) Style and stack\n",
    "fig.update_layout(\n",
    "    barmode='stack',\n",
    "    xaxis=dict(type='category', categoryorder='category ascending'),\n",
    "    xaxis_title_font_size=16,\n",
    "    yaxis_title_font_size=16,\n",
    "    legend_title_font_size=14,\n",
    "    legend_font_size=12,\n",
    "    title_x=0.5,\n",
    "    title_font_size=20,\n",
    "    margin=dict(t=80, b=120)  # extra bottom margin for long date labels\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46d3ddb",
   "metadata": {},
   "source": [
    "### Monthly Grid Loss by Price Area every month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d070f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# 1) Prepare your DataFrame\n",
    "df = big_df.copy()\n",
    "df['startTime'] = pd.to_datetime(df['startTime'], utc=True).dt.tz_convert('Europe/Oslo')\n",
    "df['month'] = df['startTime'].dt.to_period('M').astype(str)\n",
    "\n",
    "# 2) Aggregate total loss per month and priceArea\n",
    "monthly_loss = (\n",
    "    df\n",
    "    .groupby(['month', 'priceArea'])['calculatedLossQuantityKwh']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 3) Create a stacked bar chart\n",
    "fig = px.bar(\n",
    "    monthly_loss,\n",
    "    x='month',\n",
    "    y='calculatedLossQuantityKwh',\n",
    "    color='priceArea',\n",
    "    title='Monthly Grid Loss by Price Area (stacked)',\n",
    "    labels={\n",
    "        'month': 'Month',\n",
    "        'calculatedLossQuantityKwh': 'Total Loss (kWh)',\n",
    "        'priceArea': 'Price Area'\n",
    "    }\n",
    ")\n",
    "\n",
    "# 4) Stack bars and style\n",
    "fig.update_layout(\n",
    "    barmode='stack',\n",
    "    xaxis=dict(categoryorder='category ascending'),\n",
    "    xaxis_title_font_size=16,\n",
    "    yaxis_title_font_size=16,\n",
    "    legend_title_font_size=14,\n",
    "    legend_font_size=12,\n",
    "    title_x=0.5,\n",
    "    title_font_size=20,\n",
    "    margin=dict(t=80, b=80)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02548e6",
   "metadata": {},
   "source": [
    "### Monthly Grid Loss by Price Area aggregated by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3a5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# ─── PREPARE YOUR DATAFRAME ───────────────────────────────────────────────────\n",
    "df = big_df.copy()\n",
    "# parse and localize timestamps\n",
    "df['startTime'] = (\n",
    "    pd.to_datetime(df['startTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "# extract year and calendar month\n",
    "df['year']           = df['startTime'].dt.year\n",
    "df['month_num']      = df['startTime'].dt.month\n",
    "df['month_name']     = df['startTime'].dt.month_name().str.slice(stop=3)  # \"Jan\", \"Feb\", …\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# 1) Compute monthly total loss for each year‐month & priceArea\n",
    "monthly_totals = (\n",
    "    df\n",
    "    .groupby(['year','month_num','month_name','priceArea'])['calculatedLossQuantityKwh']\n",
    "    .sum()\n",
    "    .reset_index(name='monthlyLossKWh')\n",
    ")\n",
    "\n",
    "# 2) Average across years to get one value per calendar month & priceArea\n",
    "avg_calendar = (\n",
    "    monthly_totals\n",
    "    .groupby(['month_num','month_name','priceArea'])['monthlyLossKWh']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'monthlyLossKWh':'avgMonthlyLossKWh'})\n",
    ")\n",
    "\n",
    "# 3) Ensure calendar‐month ordering Jan → Dec\n",
    "month_order = [\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]\n",
    "avg_calendar['month_name'] = pd.Categorical(avg_calendar['month_name'], categories=month_order, ordered=True)\n",
    "avg_calendar = avg_calendar.sort_values('month_name')\n",
    "\n",
    "# 4) Plot a stacked bar chart\n",
    "fig = px.bar(\n",
    "    avg_calendar,\n",
    "    x='month_name',\n",
    "    y='avgMonthlyLossKWh',\n",
    "    color='priceArea',\n",
    "    title='Average Monthly Grid Loss by Price Area (Calendar Months)',\n",
    "    labels={\n",
    "        'month_name': 'Month',\n",
    "        'avgMonthlyLossKWh': 'Avg Loss (kWh)',\n",
    "        'priceArea': 'Price Area'\n",
    "    }\n",
    ")\n",
    "\n",
    "# 5) Style the chart\n",
    "fig.update_layout(\n",
    "    barmode='stack',\n",
    "    xaxis=dict(categoryorder='array', categoryarray=month_order),\n",
    "    xaxis_title_font_size=16,\n",
    "    yaxis_title_font_size=16,\n",
    "    title_font_size=20,\n",
    "    legend_title_font_size=14,\n",
    "    legend_font_size=12,\n",
    "    title_x=0.5,\n",
    "    margin=dict(t=80, b=80)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b5a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ASSUMES big_df exists with columns:\n",
    "#   'startTime', 'priceArea', 'calculatedLossQuantityKwh'\n",
    "\n",
    "# 1) Localize timestamps & extract month/season\n",
    "df = big_df.copy()\n",
    "df['startTime'] = (\n",
    "    pd.to_datetime(df['startTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "df['month'] = df['startTime'].dt.month\n",
    "df['season'] = df['month'].map(\n",
    "    lambda m: 'Summer' if m in (6,7,8)\n",
    "              else 'Winter' if m in (12,1,2)\n",
    "              else None\n",
    ")\n",
    "df = df[df['season'].notna()]\n",
    "\n",
    "# 2) Determine 5th and 95th percentiles of loss for trimming (across all PAs/seasons)\n",
    "lo, hi = df['calculatedLossQuantityKwh'].quantile([0.05, 0.95])\n",
    "\n",
    "# 3) List price areas and prepare subplot grid\n",
    "price_areas = sorted(df['priceArea'].unique())\n",
    "n = len(price_areas)\n",
    "\n",
    "# Build titles row-by-row: [PA1—Summer, PA1—Winter, PA2—Summer, PA2—Winter, …]\n",
    "subplot_titles = []\n",
    "for pa in price_areas:\n",
    "    subplot_titles += [f\"{pa} — Summer\", f\"{pa} — Winter\"]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=n, cols=2,\n",
    "    shared_xaxes='rows',\n",
    "    horizontal_spacing=0.04,\n",
    "    vertical_spacing=0.04,\n",
    "    subplot_titles=subplot_titles\n",
    ")\n",
    "\n",
    "# 4) Colors for seasons\n",
    "colors = {'Summer': '#E24A33', 'Winter': '#348ABD'}\n",
    "\n",
    "# 5) Add one histogram per (priceArea, season)\n",
    "bins = np.linspace(lo, hi, 40)\n",
    "for i, pa in enumerate(price_areas, start=1):\n",
    "    for j, season in enumerate(['Summer', 'Winter'], start=1):\n",
    "        data = (\n",
    "            df[(df['priceArea']==pa) & (df['season']==season)]\n",
    "            ['calculatedLossQuantityKwh']\n",
    "            .clip(lo, hi)\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=data,\n",
    "                xbins=dict(start=lo, end=hi, size=(hi-lo)/40),\n",
    "                marker_color=colors[season],\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=i, col=j\n",
    "        )\n",
    "\n",
    "# 6) Update axes: show tick labels on every subplot, and set the same range per row\n",
    "for i in range(1, n+1):\n",
    "    # Shared-xaxes='rows' links ranges, but we explicitly set range on first column:\n",
    "    fig.update_xaxes(range=[lo, hi], row=i, col=1)\n",
    "    # Ensure both subplots in the row show tick labels\n",
    "    fig.update_xaxes(showticklabels=True, row=i, col=1)\n",
    "    fig.update_xaxes(showticklabels=True, row=i, col=2)\n",
    "\n",
    "# 7) Label only the bottom row with an x-axis title\n",
    "fig.update_xaxes(\n",
    "    title_text=\"Loss (kWh) trimmed to 5–95 percentile\",\n",
    "    row=n, col=1\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    title_text=\"Loss (kWh) trimmed to 5–95 percentile\",\n",
    "    row=n, col=2\n",
    ")\n",
    "\n",
    "# 8) Global layout tweaks\n",
    "fig.update_layout(\n",
    "    title_text=\"Seasonal Distributions of Loss by Price Area (5–95% trimmed)\",\n",
    "    title_x=0.5,\n",
    "    height=250 * n,\n",
    "    width=800,\n",
    "    margin=dict(t=100, b=80)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b10415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ─ Assumes big_df exists with columns:\n",
    "#   'startTime', 'priceArea', 'calculatedLossQuantityKwh'\n",
    "\n",
    "# 1) Localize timestamps & extract month/season\n",
    "df = big_df.copy()\n",
    "df['startTime'] = (\n",
    "    pd.to_datetime(df['startTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "df['month'] = df['startTime'].dt.month\n",
    "df['season'] = df['month'].map(\n",
    "    lambda m: 'Summer' if m in (6,7,8)\n",
    "              else 'Winter' if m in (12,1,2)\n",
    "              else None\n",
    ")\n",
    "df = df[df['season'].notna()]\n",
    "\n",
    "# 2) Compute overall span for title\n",
    "span_start = df['startTime'].min().strftime('%Y-%m-%d %H:%M')\n",
    "span_end   = df['startTime'].max().strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "# 3) Determine 5th and 95th percentiles of loss for trimming\n",
    "lo, hi = df['calculatedLossQuantityKwh'].quantile([0.05, 0.95])\n",
    "\n",
    "# 4) List price areas and prepare subplot grid\n",
    "price_areas = sorted(df['priceArea'].unique())\n",
    "n = len(price_areas)\n",
    "subplot_titles = []\n",
    "for pa in price_areas:\n",
    "    subplot_titles += [f\"{pa} — Summer\", f\"{pa} — Winter\"]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=n, cols=2,\n",
    "    shared_xaxes='rows',\n",
    "    horizontal_spacing=0.04,\n",
    "    vertical_spacing=0.04,\n",
    "    subplot_titles=subplot_titles\n",
    ")\n",
    "\n",
    "# 5) Colors\n",
    "colors = {'Summer': '#E24A33', 'Winter': '#348ABD'}\n",
    "bins = np.linspace(lo, hi, 40)\n",
    "\n",
    "# 6) Add histograms\n",
    "for i, pa in enumerate(price_areas, start=1):\n",
    "    for j, season in enumerate(['Summer', 'Winter'], start=1):\n",
    "        data = (\n",
    "            df[(df['priceArea']==pa) & (df['season']==season)]\n",
    "              ['calculatedLossQuantityKwh']\n",
    "              .clip(lo, hi)\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=data,\n",
    "                xbins=dict(start=lo, end=hi, size=(hi-lo)/40),\n",
    "                marker_color=colors[season],\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=i, col=j\n",
    "        )\n",
    "\n",
    "# 7) Uniform x-axis range & tick labels per row\n",
    "for i in range(1, n+1):\n",
    "    fig.update_xaxes(range=[lo, hi], row=i, col=1)\n",
    "    fig.update_xaxes(showticklabels=True, row=i, col=1)\n",
    "    fig.update_xaxes(showticklabels=True, row=i, col=2)\n",
    "\n",
    "# 8) Label bottom row\n",
    "fig.update_xaxes(\n",
    "    title_text=\"Loss (kWh) trimmed to 5–95 percentile\",\n",
    "    row=n, col=1\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    title_text=\"Loss (kWh) trimmed to 5–95 percentile\",\n",
    "    row=n, col=2\n",
    ")\n",
    "\n",
    "# 9) Main title with dynamic span\n",
    "fig.update_layout(\n",
    "    title_text=(\n",
    "        f\"Seasonal Distributions of Loss by Price Area (5–95% trimmed)<br>\"\n",
    "        f\"{span_start} to {span_end} Oslo Time\"\n",
    "    ),\n",
    "    title_x=0.5,\n",
    "    height=250 * n,\n",
    "    width=800,\n",
    "    margin=dict(t=120, b=80)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gridloss_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
