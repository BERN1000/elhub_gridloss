{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fa696c9",
   "metadata": {},
   "source": [
    "# Elhub API data - Gridloss - Summerproject 2025\n",
    "\n",
    "## Visualization\n",
    "\n",
    "BjÃ¸rn Eirik Rognskog Nordbak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f640dfd4",
   "metadata": {},
   "source": [
    "### Importing data from Elhub API\n",
    "https://api.elhub.no/energy-data-api#/grid-areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7aa1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "oslo = ZoneInfo(\"Europe/Oslo\")\n",
    "\n",
    "def fetch_window(start_dt, end_dt):\n",
    "    params = {\n",
    "        \"dataset\":   \"LOSS_PER_MGA_HOUR\",\n",
    "        \"startDate\": start_dt.isoformat(),\n",
    "        \"endDate\":   end_dt.isoformat(),\n",
    "    }\n",
    "    url = \"https://api.elhub.no/energy-data/v0/grid-areas\"\n",
    "    resp = requests.get(url, params=params)\n",
    "    obj = resp.json()\n",
    "    \n",
    "    # --- safeguard: if there's no \"data\", bail with empty DF ----\n",
    "    raw = obj.get(\"data\")\n",
    "    if raw is None:\n",
    "        print(f\"  â†’ no 'data' for {start_dt.date()} â†’ {end_dt.date()}, skipping\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # otherwise flatten\n",
    "    df = pd.json_normalize(\n",
    "        raw,\n",
    "        record_path=[\"attributes\", \"lossPerMgaHour\"],\n",
    "        meta=[\n",
    "            [\"attributes\", \"eic\"],\n",
    "            [\"attributes\", \"name\"],\n",
    "            [\"attributes\", \"status\"],\n",
    "        ],\n",
    "        errors=\"ignore\"\n",
    "    ).rename(columns={\n",
    "        \"attributes.eic\":    \"eic\",\n",
    "        \"attributes.name\":   \"name\",\n",
    "        \"attributes.status\": \"status\",\n",
    "    })\n",
    "    return df\n",
    "\n",
    "# loop as before\n",
    "span_start = datetime(2023,1,1,0,0, tzinfo=oslo)\n",
    "span_end   = datetime(2025,7,1,0,0, tzinfo=oslo)\n",
    "window = timedelta(days=7)\n",
    "\n",
    "all_chunks = []\n",
    "cur = span_start\n",
    "while cur < span_end:\n",
    "    nxt = min(cur + window, span_end)\n",
    "    print(f\"Fetching {cur.date()} â†’ {nxt.date()}\")\n",
    "    dfc = fetch_window(cur, nxt)\n",
    "    all_chunks.append(dfc)\n",
    "    cur = nxt\n",
    "\n",
    "big_df = pd.concat(all_chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2273fd68",
   "metadata": {},
   "source": [
    "### Save the data to a CSV file (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb47a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Save your DataFrame to CSV\n",
    "# Replace big_df with your DataFrame variable\n",
    "big_df.to_csv('big_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375ae101",
   "metadata": {},
   "source": [
    "### Read the CSV file (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1e41fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 2. Load the DataFrame back from CSV\n",
    "# This will recreate the DataFrame exactly as it was (aside from types inference)\n",
    "big_df = pd.read_csv('big_df.csv')\n",
    "\n",
    "big_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ae7cdd",
   "metadata": {},
   "source": [
    "## Data quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2050af2f",
   "metadata": {},
   "source": [
    "### Data quality report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f7aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def humanized_dq_report_no(df):\n",
    "    # grunnleggende statistikk\n",
    "    present     = df.notnull().sum()\n",
    "    missing     = df.isnull().sum()\n",
    "    pct_missing = (missing / len(df) * 100).round(1)\n",
    "    unique_vals = df.nunique(dropna=False)\n",
    "    dtypes      = df.dtypes.astype(str)\n",
    "    \n",
    "    # oversett dtype til vennlig betegnelse\n",
    "    def friendly_dtype(dt):\n",
    "        if \"float\" in dt or \"int\" in dt:\n",
    "            return \"Numerisk\"\n",
    "        if \"datetime\" in dt:\n",
    "            return \"Dato/Tid\"\n",
    "        return \"Tekst\"\n",
    "    \n",
    "    # bygg rapporten med norske kolonnenavn\n",
    "    report = pd.DataFrame({\n",
    "        \"Kolonne\":       present.index,\n",
    "        \"Datatype\":      [friendly_dtype(d) for d in dtypes],\n",
    "        \"Tilstede\":      present.values,\n",
    "        \"Mangler\":       missing.values,\n",
    "        \"% Mangler\":     pct_missing.values,\n",
    "        \"Unike verdier\": unique_vals.values\n",
    "    })\n",
    "    \n",
    "    # spesifiser rekkefÃ¸lgen\n",
    "    cols = [\"Kolonne\", \"Datatype\", \"Tilstede\", \"Mangler\", \"% Mangler\", \"Unike verdier\"]\n",
    "    return report[cols]\n",
    "\n",
    "# generer rapport\n",
    "dq = humanized_dq_report_no(big_df)\n",
    "\n",
    "# fjern index-visning\n",
    "dq_display = dq.copy()\n",
    "dq_display.index = [\"\"] * len(dq_display)\n",
    "\n",
    "# vis med formatering\n",
    "fmt = {\n",
    "    \"Tilstede\":      \"{:,}\",\n",
    "    \"Mangler\":       \"{:,}\",\n",
    "    \"% Mangler\":     \"{:.1f}%\",\n",
    "    \"Unike verdier\": \"{:,}\"\n",
    "}\n",
    "\n",
    "dq_display.style \\\n",
    "    .format(fmt) \\\n",
    "    .set_caption(f\"Datakvalitetssammendrag ({len(big_df):,} rader Ã— {big_df.shape[1]} kolonner)\") \\\n",
    "    .set_table_styles([\n",
    "        {\n",
    "            \"selector\": \"caption\",\n",
    "            \"props\": [\n",
    "                (\"caption-side\",\"bottom\"),\n",
    "                (\"font-style\",\"italic\"),\n",
    "                (\"text-align\",\"left\"),\n",
    "            ]\n",
    "        }\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb731833",
   "metadata": {},
   "source": [
    "### Save the data quality report to a .tex table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbe31a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 1) sÃ¸rg for at output-mappen finnes\n",
    "os.makedirs(\"tabeller\", exist_ok=True)\n",
    "\n",
    "# 2) kopier og formater akkurat som fÃ¸r\n",
    "dq_tex = dq.copy()\n",
    "dq_tex[\"Tilstede\"]      = dq_tex[\"Tilstede\"].map(\"{:,}\".format)\n",
    "dq_tex[\"Mangler\"]       = dq_tex[\"Mangler\"].map(\"{:,}\".format)\n",
    "dq_tex[\"% Mangler\"]     = dq_tex[\"% Mangler\"].map(\"{:.1f}\\\\%\".format)\n",
    "dq_tex[\"Unike verdier\"] = dq_tex[\"Unike verdier\"].map(\"{:,}\".format)\n",
    "\n",
    "# 3) endre kolonneoverskrift fra \"% Mangler\" til \"\\% Mangler\"\n",
    "dq_tex = dq_tex.rename(columns={\"% Mangler\": r\"\\% Mangler\"})\n",
    "\n",
    "# 4) eksporter kun tabellen (ingen float-wrapper, caption, label osv.)\n",
    "tabular_str = dq_tex.to_latex(\n",
    "    index=False,\n",
    "    longtable=False,\n",
    "    caption=None,\n",
    "    label=None,\n",
    "    escape=False      # behold LaTeX-markup i cellene\n",
    ")\n",
    "\n",
    "# 5) skriv ut til .tex-fil\n",
    "ut_path = \"tables/datakvalitet_gridarea_tabular.tex\"\n",
    "with open(ut_path, \"w\") as f:\n",
    "    f.write(tabular_str)\n",
    "\n",
    "print(f\"Skrev tabell-fil til {ut_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fc1e8c",
   "metadata": {},
   "source": [
    "### Checking for temporal consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c453cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# â”€â”€ 1) Make sure startTime is a real datetime â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "big_df['startTime'] = pd.to_datetime(big_df['startTime'], utc=True)\n",
    "\n",
    "# â”€â”€ 2) Sort by gridArea and startTime â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df = (\n",
    "    big_df\n",
    "    .sort_values(['gridArea', 'startTime'])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# â”€â”€ 3) Compute the delta between each startTime and the previous one â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df['delta'] = df.groupby('gridArea')['startTime'].diff()\n",
    "\n",
    "# â”€â”€ 4) Filter out the perfect 1â€‘hour steps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "expected = pd.Timedelta(hours=1)\n",
    "irregular = df[df['delta'].notna() & (df['delta'] != expected)]\n",
    "\n",
    "# â”€â”€ 5) Inspect results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(f\"ðŸ”Ž Found {len(irregular)} irregular intervals across \"\n",
    "      f\"{irregular['gridArea'].nunique()} gridAreas\\n\")\n",
    "\n",
    "# show first 20 problematic rows\n",
    "display(irregular[['gridArea', 'startTime', 'delta']].head(20))\n",
    "\n",
    "# quick summary per gridArea\n",
    "summary = (\n",
    "    irregular\n",
    "    .groupby('gridArea')['delta']\n",
    "    .agg(count='count', total='sum', average='mean', maximum='max')\n",
    "    .reset_index()\n",
    ")\n",
    "print(\"â€” Summary by gridArea â€”\")\n",
    "display(summary)\n",
    "\n",
    "# (optional) write out to CSV for deeper analysis\n",
    "irregular.to_csv('irregular_intervals.csv', index=False)\n",
    "summary.to_csv('irregular_summary.csv', index=False)\n",
    "print(\"\\nâ–¶ï¸  Detailed rows â†’ irregular_intervals.csv\")\n",
    "print(\"â–¶ï¸  Summary stats â†’ irregular_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9ffb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "areas = ['AEN1 RN', 'AEN2 DN']  # â† swap in any gridAreas you want\n",
    "\n",
    "for area in areas:\n",
    "    sub = (\n",
    "        df[df['gridArea'] == area]\n",
    "        .sort_values('startTime')\n",
    "        .reset_index(drop=True)\n",
    "        .copy()\n",
    "    )\n",
    "    # compute delta (hours) and track previous timestamp\n",
    "    sub['delta_h']   = sub['startTime'].diff().dt.total_seconds() / 3600\n",
    "    sub['prev_time'] = sub['startTime'].shift(1)\n",
    "    \n",
    "    # pick out only the â€œrealâ€ gaps\n",
    "    gaps = sub[(sub['delta_h'].notna()) & (sub['delta_h'] != 1)]\n",
    "    \n",
    "    # 1) Print each gapâ€™s start/end\n",
    "    print(f\"\\nâš ï¸  Gaps in {area}:\")\n",
    "    if gaps.empty:\n",
    "        print(\"   (none!)\")\n",
    "    else:\n",
    "        for _, row in gaps.iterrows():\n",
    "            print(f\"   â€¢ from {row['prev_time']} â†’ {row['startTime']}  (Î”â€¯=â€¯{row['delta_h']:.1f}â€¯h)\")\n",
    "    \n",
    "    # 2) Plot the full deltaâ€‘series with highlighted spikes\n",
    "    fig, ax = plt.subplots(figsize=(10,4))\n",
    "    ax.plot(sub['startTime'], sub['delta_h'], label='hourly Î”')\n",
    "    ax.scatter(gaps['startTime'], gaps['delta_h'], color='red', zorder=5, label='gaps')\n",
    "    for x in gaps['startTime']:\n",
    "        ax.axvline(x=x, color='red', alpha=0.3)\n",
    "    \n",
    "    # sparse, readable xâ€‘ticks every 2 months\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    ax.set_title(f\"Hourly Î” between startTimes â€” {area}\")\n",
    "    ax.set_ylabel(\"Î” (hours)\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0510b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# â€” convert the Timedelta column 'delta' into hours (float)\n",
    "hrs = irregular['delta'].dt.total_seconds() / 3600\n",
    "\n",
    "# 1) What unique gapâ€sizes (in hours) do we see globally?\n",
    "global_hours = np.sort(hrs.unique())\n",
    "print(\"ðŸ”Â All distinct irregular Î” (hours):\", global_hours)\n",
    "\n",
    "if len(global_hours) == 1:\n",
    "    print(f\"âœ…Â Yes â€” every gap is exactly {global_hours[0]:.1f}â€¯hours.\")\n",
    "else:\n",
    "    print(\"âš ï¸Â No â€” there are multiple gap sizes in the data.\")\n",
    "\n",
    "# 2) Check per gridArea whether each area only has that one gap size\n",
    "per_area = (\n",
    "    irregular\n",
    "    .assign(hours=hrs)\n",
    "    .groupby('gridArea')['hours']\n",
    "    .agg(n_unique='nunique', min_h='min', max_h='max')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# how many areas have more than one gap size?\n",
    "bad = per_area[per_area['n_unique'] > 1]\n",
    "if bad.empty:\n",
    "    print(\"âœ…Â Every gridArea has a single, consistent gap size.\")\n",
    "else:\n",
    "    print(f\"âš ï¸Â {len(bad)} gridAreas have >1 gap size (theyâ€™d show up below):\")\n",
    "    display(bad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8925cd01",
   "metadata": {},
   "source": [
    "## Exploring the Elhub API gridloss data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b4fbf4",
   "metadata": {},
   "source": [
    "### Unique eic codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23338230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique EIC codes\n",
    "unique_eic_count = big_df['eic'].nunique()\n",
    "print(f\"Number of unique EIC codes: {unique_eic_count}\")\n",
    "\n",
    "# List them out\n",
    "unique_eics = big_df['eic'].unique()\n",
    "print(unique_eics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5909a043",
   "metadata": {},
   "source": [
    "### Unique names entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique name entries\n",
    "unique_name_count = big_df['name'].nunique()\n",
    "print(f\"Number of unique names: {unique_name_count}\")\n",
    "\n",
    "# List all unique names\n",
    "unique_names = big_df['name'].unique()\n",
    "print(unique_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22d7c4b",
   "metadata": {},
   "source": [
    "### Unique gridArea entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caefa98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique gridArea entries\n",
    "unique_gridarea_count = big_df['gridArea'].nunique()\n",
    "print(f\"Number of unique grid areas: {unique_gridarea_count}\")\n",
    "\n",
    "# List all unique gridArea codes\n",
    "unique_gridareas = big_df['gridArea'].unique()\n",
    "print(unique_gridareas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599e567b",
   "metadata": {},
   "source": [
    "### Unique priceArea entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a05441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique priceArea entries\n",
    "unique_pricearea_count = big_df['priceArea'].nunique()\n",
    "print(f\"Number of unique price areas: {unique_pricearea_count}\")\n",
    "\n",
    "# List all unique priceArea codes\n",
    "unique_priceareas = big_df['priceArea'].unique()\n",
    "print(unique_priceareas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5522d301",
   "metadata": {},
   "source": [
    "### Average hourly grid loss per price area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c591ee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# â”€â”€â”€ FONT SIZE SETTINGS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "TITLE_FS        = 24\n",
    "AXIS_TITLE_FS   = 20\n",
    "TICK_FS         = 18\n",
    "BAR_TEXT_FS     = 18\n",
    "FONT_FAMILY     = \"Roboto\"  # Elhub font (requires it to be installed locally)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Elhub brand colors (primÃ¦r + sekundÃ¦r)\n",
    "elhub_colors = [\n",
    "    \"#212148\",  # MÃ¸rk Lilla\n",
    "    \"#7fb48a\",  # GrÃ¸nn\n",
    "    \"#5369b2\",  # BlÃ¥\n",
    "    \"#05677d\",  # BlÃ¥-grÃ¸nn\n",
    "    \"#886599\",  # Lilla\n",
    "    \"#d58000\",  # Oker\n",
    "]\n",
    "\n",
    "# â”€â”€â”€ LOAD & PREPARE DATA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Assume `big_df` is already in your namespace. If not, load it here:\n",
    "# big_df = pd.read_csv(\"path_to_your_data.csv\")\n",
    "\n",
    "# Make a working copy\n",
    "df = big_df.copy()\n",
    "\n",
    "# Ensure startTime is datetime64[ns, UTC] â†’ datetime64[ns, Europe/Oslo]\n",
    "df['startTime'] = (\n",
    "    pd.to_datetime(df['startTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "\n",
    "# Extract span dates for title\n",
    "span_start = df['startTime'].min().date().isoformat()\n",
    "span_end   = df['startTime'].max().date().isoformat()\n",
    "\n",
    "# â”€â”€â”€ AGGREGATION: AVERAGE HOURLY LOSS PER PRICE AREA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Compute the mean loss per hourly observation, grouped by priceArea\n",
    "avg_hourly_area = (\n",
    "    df\n",
    "    .groupby('priceArea')['calculatedLossQuantityKwh']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'calculatedLossQuantityKwh':'avgHourlyLossKWh'})\n",
    ")\n",
    "\n",
    "# â”€â”€â”€ BUILD & STYLE THE BAR CHART â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Dynamic title\n",
    "title_text = (\n",
    "    f\"Average Hourly Loss per Price Area\\n\"\n",
    "    f\"({span_start} to {span_end})\"\n",
    ")\n",
    "\n",
    "fig = px.bar(\n",
    "    avg_hourly_area,\n",
    "    x='priceArea',\n",
    "    y='avgHourlyLossKWh',\n",
    "    color='priceArea',\n",
    "    text='avgHourlyLossKWh',\n",
    "    title=title_text,\n",
    "    labels={'avgHourlyLossKWh': 'Avg Hourly Loss (kWh)'},\n",
    "    color_discrete_sequence=elhub_colors\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    texttemplate='%{text:,.0f}',\n",
    "    textposition='inside',\n",
    "    textfont=dict(color='white', size=BAR_TEXT_FS),\n",
    "    hovertemplate='%{x}: %{y:,.0f} kWh'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_font=dict(size=TITLE_FS, family=FONT_FAMILY),\n",
    "    title_x=0.5,\n",
    "    font=dict(family=FONT_FAMILY),\n",
    "    xaxis=dict(\n",
    "        title='',                # no x-axis title\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    showlegend=False,\n",
    "    margin=dict(t=100, b=80),\n",
    "    plot_bgcolor='white',\n",
    "    paper_bgcolor='white'\n",
    ")\n",
    "\n",
    "# Show interactive chart\n",
    "fig.show()\n",
    "\n",
    "# â”€â”€â”€ EXPORT TO PDF â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "output_path = \"average_hourly_loss_per_price_area_bar.pdf\"\n",
    "fig.write_image(\n",
    "    output_path,\n",
    "    format=\"pdf\",\n",
    "    width=1000,\n",
    "    height=700,\n",
    "    scale=1\n",
    ")\n",
    "print(f\"âœ… Saved PDF to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e17e1ec",
   "metadata": {},
   "source": [
    "### Average daily grid loss per price area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d1237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# â”€â”€â”€ FONT SIZE SETTINGS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "TITLE_FS        = 24\n",
    "AXIS_TITLE_FS   = 20\n",
    "TICK_FS         = 18\n",
    "BAR_TEXT_FS     = 18\n",
    "FONT_FAMILY     = \"Roboto\"  # Elhub font (requires it to be installed locally)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Elhub brand colors (primÃ¦r + sekundÃ¦r)\n",
    "elhub_colors = [\n",
    "    \"#212148\",  # MÃ¸rk Lilla\n",
    "    \"#7fb48a\",  # GrÃ¸nn\n",
    "    \"#5369b2\",  # BlÃ¥\n",
    "    \"#05677d\",  # BlÃ¥-grÃ¸nn\n",
    "    \"#886599\",  # Lilla\n",
    "    \"#d58000\",  # Oker\n",
    "]\n",
    "\n",
    "# Ensure startTime is localized\n",
    "df = big_df.copy()\n",
    "df['startTime'] = (\n",
    "    pd.to_datetime(df['startTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "\n",
    "# Span for dynamic title\n",
    "span_start = df['startTime'].min().date().isoformat()\n",
    "span_end   = df['startTime'].max().date().isoformat()\n",
    "\n",
    "# Daily aggregation\n",
    "df['date'] = df['startTime'].dt.date.astype(str)\n",
    "daily_totals = (\n",
    "    df.groupby(['date', 'priceArea'])['calculatedLossQuantityKwh']\n",
    "      .sum().reset_index()\n",
    ")\n",
    "avg_daily = (\n",
    "    daily_totals\n",
    "    .groupby('priceArea')['calculatedLossQuantityKwh']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'calculatedLossQuantityKwh':'avgDailyLossKWh'})\n",
    ")\n",
    "\n",
    "# Title\n",
    "title_text = (\n",
    "    f\"Average Daily Loss per Price Area\\n\"\n",
    "    f\"({span_start} to {span_end})\"\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig = px.bar(\n",
    "    avg_daily,\n",
    "    x='priceArea',\n",
    "    y='avgDailyLossKWh',\n",
    "    color='priceArea',\n",
    "    text='avgDailyLossKWh',\n",
    "    title=title_text,\n",
    "    labels={'avgDailyLossKWh': 'Avg Daily Loss (kWh)'},\n",
    "    color_discrete_sequence=elhub_colors\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    texttemplate='%{text:,.0f}',\n",
    "    textposition='inside',\n",
    "    textfont=dict(color='white', size=BAR_TEXT_FS),\n",
    "    cliponaxis=False\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_font=dict(size=TITLE_FS, family=FONT_FAMILY),\n",
    "    title_x=0.5,\n",
    "    font=dict(family=FONT_FAMILY),\n",
    "    xaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    showlegend=False,\n",
    "    margin=dict(t=100, b=80),\n",
    "    plot_bgcolor='white',\n",
    "    paper_bgcolor='white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Export to PDF\n",
    "output_path = \"average_daily_loss_per_price_area_bar.pdf\"\n",
    "fig.write_image(\n",
    "    output_path,\n",
    "    format=\"pdf\",\n",
    "    width=1000,\n",
    "    height=700,\n",
    "    scale=1\n",
    ")\n",
    "print(f\"âœ… Saved PDF to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37d198c",
   "metadata": {},
   "source": [
    "### Average monthly grid loss per price area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb969928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# â”€â”€â”€ FONT SIZE SETTINGS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "TITLE_FS        = 24\n",
    "AXIS_TITLE_FS   = 20\n",
    "TICK_FS         = 18\n",
    "BAR_TEXT_FS     = 18\n",
    "FONT_FAMILY     = \"Roboto\"  # Elhub font (requires it to be installed locally)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Elhub brand colors (primÃ¦r + sekundÃ¦r)\n",
    "elhub_colors = [\n",
    "    \"#212148\",  # MÃ¸rk Lilla\n",
    "    \"#7fb48a\",  # GrÃ¸nn\n",
    "    \"#5369b2\",  # BlÃ¥\n",
    "    \"#05677d\",  # BlÃ¥-grÃ¸nn\n",
    "    \"#886599\",  # Lilla\n",
    "    \"#d58000\",  # Oker\n",
    "]\n",
    "\n",
    "# Ensure startTime is localized\n",
    "df = big_df.copy()\n",
    "df['startTime'] = (\n",
    "    pd.to_datetime(df['startTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "\n",
    "# Span for dynamic title (use first and last month)\n",
    "span_start = df['startTime'].min().to_period('M').to_timestamp().date().isoformat()\n",
    "span_end   = df['startTime'].max().to_period('M').to_timestamp().date().isoformat()\n",
    "\n",
    "# Monthly aggregation\n",
    "df['month'] = df['startTime'].dt.to_period('M').astype(str)  # e.g. \"2025-06\"\n",
    "monthly_totals = (\n",
    "    df.groupby(['month', 'priceArea'])['calculatedLossQuantityKwh']\n",
    "      .sum()\n",
    "      .reset_index()\n",
    ")\n",
    "avg_monthly = (\n",
    "    monthly_totals\n",
    "    .groupby('priceArea')['calculatedLossQuantityKwh']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'calculatedLossQuantityKwh':'avgMonthlyLossKWh'})\n",
    ")\n",
    "\n",
    "# Title\n",
    "title_text = (\n",
    "    f\"Average Monthly Loss per Price Area\\n\"\n",
    "    f\"({span_start} to {span_end})\"\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig = px.bar(\n",
    "    avg_monthly,\n",
    "    x='priceArea',\n",
    "    y='avgMonthlyLossKWh',\n",
    "    color='priceArea',\n",
    "    text='avgMonthlyLossKWh',\n",
    "    title=title_text,\n",
    "    labels={'avgMonthlyLossKWh': 'Avg Monthly Loss (kWh)'},\n",
    "    color_discrete_sequence=elhub_colors\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    texttemplate='%{text:,.0f}',\n",
    "    textposition='inside',\n",
    "    textfont=dict(color='white', size=BAR_TEXT_FS),\n",
    "    cliponaxis=False\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_font=dict(size=TITLE_FS, family=FONT_FAMILY),\n",
    "    title_x=0.5,\n",
    "    font=dict(family=FONT_FAMILY),\n",
    "    xaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    showlegend=False,\n",
    "    margin=dict(t=100, b=80),\n",
    "    plot_bgcolor='white',\n",
    "    paper_bgcolor='white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Export to PDF\n",
    "output_path = \"average_monthly_loss_per_price_area_bar.pdf\"\n",
    "fig.write_image(\n",
    "    output_path,\n",
    "    format=\"pdf\",\n",
    "    width=1000,\n",
    "    height=700,\n",
    "    scale=1\n",
    ")\n",
    "print(f\"âœ… Saved PDF to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05facf98",
   "metadata": {},
   "source": [
    "### Diurnal Profile of Grid Loss - sorted by price area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4394f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# â”€â”€â”€ FONT SIZE SETTINGS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "TITLE_FS      = 24\n",
    "AXIS_TITLE_FS = 20\n",
    "TICK_FS       = 18\n",
    "MARKER_SIZE   = 8\n",
    "FONT_FAMILY   = \"Roboto\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Elhub brand colors (primÃ¦r + sekundÃ¦r)\n",
    "elhub_colors = [\n",
    "    \"#212148\",  # MÃ¸rk Lilla\n",
    "    \"#7fb48a\",  # GrÃ¸nn\n",
    "    \"#5369b2\",  # BlÃ¥\n",
    "    \"#05677d\",  # BlÃ¥-grÃ¸nn\n",
    "    \"#886599\",  # Lilla\n",
    "    \"#d58000\",  # Oker\n",
    "]\n",
    "\n",
    "# 1) Ensure startTime is localized\n",
    "df = big_df.copy()\n",
    "df['startTime'] = (\n",
    "    pd.to_datetime(df['startTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "\n",
    "# 2) Span for dynamic title\n",
    "span_start = df['startTime'].min().date().isoformat()\n",
    "span_end   = df['startTime'].max().date().isoformat()\n",
    "\n",
    "# 3) Extract hour of day\n",
    "df['hour'] = df['startTime'].dt.hour\n",
    "\n",
    "# 4) Compute average loss per hour across all days, per priceArea\n",
    "avg_hourly = (\n",
    "    df\n",
    "    .groupby(['hour', 'priceArea'], observed=True)['calculatedLossQuantityKwh']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'calculatedLossQuantityKwh':'avgHourlyLossKWh'})\n",
    ")\n",
    "\n",
    "# 5) Compute each priceAreaâ€™s share of that hourâ€™s total\n",
    "hourly_totals = avg_hourly.groupby('hour')['avgHourlyLossKWh'].transform('sum')\n",
    "avg_hourly['pctOfHour'] = avg_hourly['avgHourlyLossKWh'] / hourly_totals\n",
    "\n",
    "# 6) Title\n",
    "title_text = (\n",
    "    f\"Average Hourly Loss per Price Area\\n\"\n",
    "    f\"({span_start} to {span_end})\"\n",
    ")\n",
    "\n",
    "# 7) Plot, carrying priceArea & pctOfHour in custom_data\n",
    "fig = px.line(\n",
    "    avg_hourly,\n",
    "    x='hour',\n",
    "    y='avgHourlyLossKWh',\n",
    "    color='priceArea',\n",
    "    custom_data=['priceArea','pctOfHour'],\n",
    "    markers=True,\n",
    "    title=title_text,\n",
    "    labels={\n",
    "        'hour': 'Hour of Day',\n",
    "        'avgHourlyLossKWh': 'Avg Hourly Loss (kWh)'\n",
    "    },\n",
    "    color_discrete_sequence=elhub_colors\n",
    ")\n",
    "\n",
    "# 8) Style traces & hovertemplate\n",
    "fig.update_traces(\n",
    "    marker=dict(size=MARKER_SIZE),\n",
    "    line=dict(width=3),\n",
    "    hovertemplate=(\n",
    "        \"%{y:,.0f} kWh<br>\"\n",
    "        \"Hour: %{x}<br>\"\n",
    "        \"Area: %{customdata[0]}<br>\"\n",
    "        \"Share: %{customdata[1]:.1%}\"\n",
    "        \"<extra></extra>\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 9) Layout styling\n",
    "fig.update_layout(\n",
    "    title_font=dict(size=TITLE_FS, family=FONT_FAMILY),\n",
    "    title_x=0.5,\n",
    "    font=dict(family=FONT_FAMILY),\n",
    "    xaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS),\n",
    "        dtick=1\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    legend_title_text='Price Area',\n",
    "    legend=dict(\n",
    "        title_font_size=AXIS_TITLE_FS,\n",
    "        font_size=TICK_FS,\n",
    "        orientation='h',\n",
    "        yanchor='bottom',\n",
    "        y=1.02,\n",
    "        xanchor='center',\n",
    "        x=0.5\n",
    "    ),\n",
    "    margin=dict(t=100, b=80),\n",
    "    plot_bgcolor='white',\n",
    "    paper_bgcolor='white'\n",
    ")\n",
    "\n",
    "# 10) Show & export\n",
    "fig.show()\n",
    "\n",
    "output_path = \"diurnal_profile_loss_per_price_area.pdf\"\n",
    "fig.write_image(\n",
    "    output_path,\n",
    "    format=\"pdf\",\n",
    "    width=1000,\n",
    "    height=700,\n",
    "    scale=1\n",
    ")\n",
    "print(f\"âœ… Saved PDF to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ccc219",
   "metadata": {},
   "source": [
    "### Diurnal Profile of Grid Loss - sorted by season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a9ca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# â”€â”€â”€ FONT SIZE SETTINGS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "TITLE_FS      = 24\n",
    "AXIS_TITLE_FS = 20\n",
    "TICK_FS       = 18\n",
    "MARKER_SIZE   = 8\n",
    "FONT_FAMILY   = \"Roboto\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Elhub brand colors (weâ€™ll use the first four for the four seasons)\n",
    "season_colors = [\n",
    "    \"#212148\",  # winter (MÃ¸rk Lilla)\n",
    "    \"#7fb48a\",  # spring (GrÃ¸nn)\n",
    "    \"#5369b2\",  # summer (BlÃ¥)\n",
    "    \"#05677d\",  # autumn (BlÃ¥-grÃ¸nn)\n",
    "]\n",
    "\n",
    "# 1) Copy & localize timestamps\n",
    "df = big_df.copy()\n",
    "df['startTime'] = (\n",
    "    pd.to_datetime(df['startTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "\n",
    "# 2) Build dynamic title span\n",
    "span_start = df['startTime'].min().date().isoformat()\n",
    "span_end   = df['startTime'].max().date().isoformat()\n",
    "\n",
    "# 3) Extract month & hour\n",
    "df['month'] = df['startTime'].dt.month\n",
    "df['hour']  = df['startTime'].dt.hour\n",
    "\n",
    "# 4) Map month â†’ season\n",
    "season_map = {\n",
    "    **dict.fromkeys([12, 1, 2],   'winter'),\n",
    "    **dict.fromkeys([3, 4, 5],    'spring'),\n",
    "    **dict.fromkeys([6, 7, 8],    'summer'),\n",
    "    **dict.fromkeys([9, 10, 11],  'autumn'),\n",
    "}\n",
    "df['season'] = df['month'].map(season_map)\n",
    "\n",
    "# 5) Enforce season ordering\n",
    "season_cat = CategoricalDtype(['winter','spring','summer','autumn'], ordered=True)\n",
    "df['season'] = df['season'].astype(season_cat)\n",
    "\n",
    "# 6) Compute avg loss per hour & season\n",
    "avg_season_hourly = (\n",
    "    df\n",
    "    .groupby(['season', 'hour'], observed=True)['calculatedLossQuantityKwh']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'calculatedLossQuantityKwh': 'avgHourlyLossKWh'})\n",
    ")\n",
    "\n",
    "# 7) Compute each seasonâ€™s share of that hourâ€™s total\n",
    "hourly_totals = avg_season_hourly.groupby('hour')['avgHourlyLossKWh'].transform('sum')\n",
    "avg_season_hourly['pctOfHour'] = avg_season_hourly['avgHourlyLossKWh'] / hourly_totals\n",
    "\n",
    "# 8) Title text\n",
    "title_text = (\n",
    "    f\"Average Hourly Loss by Season\\n\"\n",
    "    f\"({span_start} to {span_end})\"\n",
    ")\n",
    "\n",
    "# 9) Create the line chart, carrying season & pctOfHour in custom_data\n",
    "fig = px.line(\n",
    "    avg_season_hourly,\n",
    "    x='hour',\n",
    "    y='avgHourlyLossKWh',\n",
    "    color='season',\n",
    "    custom_data=['season', 'pctOfHour'],\n",
    "    markers=True,\n",
    "    title=title_text,\n",
    "    labels={\n",
    "        'hour': 'Hour of Day',\n",
    "        'avgHourlyLossKWh': 'Avg Hourly Loss (kWh)',\n",
    "        'season': 'Season'\n",
    "    },\n",
    "    color_discrete_sequence=season_colors\n",
    ")\n",
    "\n",
    "# 10) Style traces & hovertemplate\n",
    "fig.update_traces(\n",
    "    marker=dict(size=MARKER_SIZE),\n",
    "    line=dict(width=3),\n",
    "    hovertemplate=(\n",
    "        \"%{y:,.0f} kWh<br>\"\n",
    "        \"Hour: %{x}<br>\"\n",
    "        \"Season: %{customdata[0]}<br>\"\n",
    "        \"Share: %{customdata[1]:.1%}\"\n",
    "        \"<extra></extra>\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 11) Layout styling\n",
    "fig.update_layout(\n",
    "    title_font=dict(size=TITLE_FS, family=FONT_FAMILY),\n",
    "    title_x=0.5,\n",
    "    font=dict(family=FONT_FAMILY),\n",
    "    xaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS),\n",
    "        dtick=1\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    legend_title_text='Season',\n",
    "    legend=dict(\n",
    "        title_font_size=AXIS_TITLE_FS,\n",
    "        font_size=TICK_FS,\n",
    "        orientation='h',\n",
    "        yanchor='bottom',\n",
    "        y=1.02,\n",
    "        xanchor='center',\n",
    "        x=0.5\n",
    "    ),\n",
    "    margin=dict(t=100, b=80),\n",
    "    plot_bgcolor='white',\n",
    "    paper_bgcolor='white'\n",
    ")\n",
    "\n",
    "# 12) Show & export\n",
    "fig.show()\n",
    "\n",
    "output_path = \"diurnal_profile_loss_by_season.pdf\"\n",
    "fig.write_image(\n",
    "    output_path,\n",
    "    format=\"pdf\",\n",
    "    width=1000,\n",
    "    height=700,\n",
    "    scale=1\n",
    ")\n",
    "print(f\"âœ… Saved PDF to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd8ece1",
   "metadata": {},
   "source": [
    "### Average hourly net infeed in kwh per price area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78355985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# â”€â”€â”€ FONT SIZE & FAMILY SETTINGS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "TITLE_FS        = 24\n",
    "AXIS_TITLE_FS   = 20\n",
    "TICK_FS         = 18\n",
    "BAR_TEXT_FS     = 18\n",
    "FONT_FAMILY     = \"Roboto\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "elhub_colors = [\n",
    "    \"#212148\", \"#7fb48a\", \"#5369b2\",\n",
    "    \"#05677d\", \"#886599\", \"#d58000\",\n",
    "]\n",
    "\n",
    "# 1) Parse startTime as UTC then convert to Oslo\n",
    "df = big_df.copy()\n",
    "df['startTime'] = (\n",
    "    pd.to_datetime(df['startTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "\n",
    "# 2) Determine span for title (floor to hour)\n",
    "span_start = df['startTime'].min().floor('h').strftime('%Y-%m-%d %H:00')\n",
    "span_end   = df['startTime'].max().floor('h').strftime('%Y-%m-%d %H:00')\n",
    "\n",
    "# 3) Extract hour (YYYY-MM-DD HH:00)\n",
    "df['hour'] = df['startTime'].dt.floor('h').astype(str)\n",
    "\n",
    "# 4) Sum net infeed into hourly totals per priceArea\n",
    "hourly_totals = (\n",
    "    df\n",
    "    .groupby(['hour', 'priceArea'])['netInfeedQuantityKwh']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 5) Compute the average of those hourly totals for each priceArea\n",
    "avg_hourly_infeed = (\n",
    "    hourly_totals\n",
    "    .groupby('priceArea')['netInfeedQuantityKwh']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'netInfeedQuantityKwh':'avgHourlyInfeedKWh'})\n",
    ")\n",
    "\n",
    "# 6) Build dynamic title\n",
    "title_text = (\n",
    "    f\"Average Hourly Net Infeed per Price Area\\n\"\n",
    "    f\"({span_start} to {span_end})\"\n",
    ")\n",
    "\n",
    "# 7) Create the bar chart with Elhub colours\n",
    "fig = px.bar(\n",
    "    avg_hourly_infeed,\n",
    "    x='priceArea',\n",
    "    y='avgHourlyInfeedKWh',\n",
    "    color='priceArea',\n",
    "    text='avgHourlyInfeedKWh',\n",
    "    title=title_text,\n",
    "    labels={'avgHourlyInfeedKWh':'Avg Hourly Net Infeed (kWh)'},\n",
    "    color_discrete_sequence=elhub_colors\n",
    ")\n",
    "\n",
    "# 8) Place values inside bars in white for contrast\n",
    "fig.update_traces(\n",
    "    texttemplate='%{text:,.0f}',\n",
    "    textposition='inside',\n",
    "    textfont=dict(color='white', size=BAR_TEXT_FS),\n",
    "    cliponaxis=False\n",
    ")\n",
    "\n",
    "# 9) Style the layout, center title, set Roboto\n",
    "fig.update_layout(\n",
    "    title_font=dict(size=TITLE_FS, family=FONT_FAMILY),\n",
    "    title_x=0.5,\n",
    "    font=dict(family=FONT_FAMILY),\n",
    "    xaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    showlegend=False,\n",
    "    margin=dict(t=100, b=80),\n",
    "    plot_bgcolor='white',\n",
    "    paper_bgcolor='white'\n",
    ")\n",
    "\n",
    "# 10) Render\n",
    "fig.show()\n",
    "\n",
    "# 11) Export to PDF\n",
    "output_path = \"average_hourly_net_infeed_per_price_area.pdf\"\n",
    "fig.write_image(\n",
    "    output_path,\n",
    "    format=\"pdf\",\n",
    "    width=1000,\n",
    "    height=700,\n",
    "    scale=1\n",
    ")\n",
    "print(f\"âœ… Saved PDF to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb0ed3c",
   "metadata": {},
   "source": [
    "### Average daily net infeed in kwh per price area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25e06d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# â”€â”€â”€ FONT SIZE & FAMILY SETTINGS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "TITLE_FS        = 24   # plot title\n",
    "AXIS_TITLE_FS   = 20   # x/y axis titles\n",
    "TICK_FS         = 18   # x/y tick labels\n",
    "BAR_TEXT_FS     = 18   # number labels inside bars\n",
    "FONT_FAMILY     = \"Roboto\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Elhub brand colors\n",
    "elhub_colors = [\n",
    "    \"#212148\",  # MÃ¸rk Lilla\n",
    "    \"#7fb48a\",  # GrÃ¸nn\n",
    "    \"#5369b2\",  # BlÃ¥\n",
    "    \"#05677d\",  # BlÃ¥-grÃ¸nn\n",
    "    \"#886599\",  # Lilla\n",
    "    \"#d58000\",  # Oker\n",
    "]\n",
    "\n",
    "# 1) Parse startTime as UTC then convert to Oslo\n",
    "df = big_df.copy()\n",
    "df['startTime'] = (\n",
    "    pd.to_datetime(df['startTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "\n",
    "# 2) Determine span for title\n",
    "span_start = df['startTime'].min().date().isoformat()\n",
    "span_end   = df['startTime'].max().date().isoformat()\n",
    "\n",
    "# 3) Extract date (day)\n",
    "df['date'] = df['startTime'].dt.date.astype(str)\n",
    "\n",
    "# 4) Sum hourly infeed into daily totals per priceArea\n",
    "daily_totals = (\n",
    "    df\n",
    "    .groupby(['date', 'priceArea'])['netInfeedQuantityKwh']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 5) Compute the average of those daily totals for each priceArea\n",
    "avg_daily_infeed = (\n",
    "    daily_totals\n",
    "    .groupby('priceArea')['netInfeedQuantityKwh']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'netInfeedQuantityKwh':'avgDailyInfeedKWh'})\n",
    ")\n",
    "\n",
    "# 6) Build dynamic title\n",
    "title_text = (\n",
    "    f\"Average Daily Net Infeed per Price Area\\n\"\n",
    "    f\"({span_start} to {span_end})\"\n",
    ")\n",
    "\n",
    "# 7) Create the bar chart with Elhub colours\n",
    "fig = px.bar(\n",
    "    avg_daily_infeed,\n",
    "    x='priceArea',\n",
    "    y='avgDailyInfeedKWh',\n",
    "    color='priceArea',\n",
    "    text='avgDailyInfeedKWh',\n",
    "    title=title_text,\n",
    "    labels={'avgDailyInfeedKWh':'Avg Daily Net Infeed (kWh)'},\n",
    "    color_discrete_sequence=elhub_colors\n",
    ")\n",
    "\n",
    "# 8) Place values inside bars in white for contrast\n",
    "fig.update_traces(\n",
    "    texttemplate='%{text:,.0f}',\n",
    "    textposition='inside',\n",
    "    textfont=dict(color='white', size=BAR_TEXT_FS),\n",
    "    cliponaxis=False\n",
    ")\n",
    "\n",
    "# 9) Style the layout, center title, set Roboto\n",
    "fig.update_layout(\n",
    "    title_font=dict(size=TITLE_FS, family=FONT_FAMILY),\n",
    "    title_x=0.5,\n",
    "    font=dict(family=FONT_FAMILY),\n",
    "    xaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    showlegend=False,\n",
    "    margin=dict(t=100, b=80),\n",
    "    plot_bgcolor='white',\n",
    "    paper_bgcolor='white'\n",
    ")\n",
    "\n",
    "# 10) Render\n",
    "fig.show()\n",
    "\n",
    "# 11) Export to PDF\n",
    "output_path = \"average_daily_net_infeed_per_price_area.pdf\"\n",
    "fig.write_image(\n",
    "    output_path,\n",
    "    format=\"pdf\",\n",
    "    width=1000,\n",
    "    height=700,\n",
    "    scale=1\n",
    ")\n",
    "print(f\"âœ… Saved PDF to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45933d8a",
   "metadata": {},
   "source": [
    "### Average monthly net infeed in kwh per price area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd332ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# â”€â”€â”€ FONT SIZE & FAMILY SETTINGS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "TITLE_FS        = 24\n",
    "AXIS_TITLE_FS   = 20\n",
    "TICK_FS         = 18\n",
    "BAR_TEXT_FS     = 18\n",
    "FONT_FAMILY     = \"Roboto\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "elhub_colors = [\n",
    "    \"#212148\", \"#7fb48a\", \"#5369b2\",\n",
    "    \"#05677d\", \"#886599\", \"#d58000\",\n",
    "]\n",
    "\n",
    "# 1) Parse startTime as UTC then convert to Oslo\n",
    "df = big_df.copy()\n",
    "df['startTime'] = (\n",
    "    pd.to_datetime(df['startTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "\n",
    "# 2) Determine span for title\n",
    "span_start = df['startTime'].min().date().isoformat()\n",
    "span_end   = df['startTime'].max().date().isoformat()\n",
    "\n",
    "# â”€â”€â”€ Modify here for MONTHLY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 3) Extract year-month string\n",
    "df['month'] = df['startTime'].dt.to_period('M').astype(str)\n",
    "\n",
    "# 4) Sum hourly infeed into **monthly** totals per priceArea\n",
    "monthly_totals = (\n",
    "    df\n",
    "    .groupby(['month', 'priceArea'])['netInfeedQuantityKwh']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 5) Compute the average of those monthly totals for each priceArea\n",
    "avg_monthly_infeed = (\n",
    "    monthly_totals\n",
    "    .groupby('priceArea')['netInfeedQuantityKwh']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'netInfeedQuantityKwh':'avgMonthlyInfeedKWh'})\n",
    ")\n",
    "\n",
    "# 6) Build dynamic title\n",
    "title_text = (\n",
    "    f\"Average Monthly Net Infeed per Price Area\\n\"\n",
    "    f\"({span_start} to {span_end})\"\n",
    ")\n",
    "\n",
    "# â”€â”€â”€ Plot exactly as before, but using avg_monthly_infeed â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "fig = px.bar(\n",
    "    avg_monthly_infeed,\n",
    "    x='priceArea',\n",
    "    y='avgMonthlyInfeedKWh',\n",
    "    color='priceArea',\n",
    "    text='avgMonthlyInfeedKWh',\n",
    "    title=title_text,\n",
    "    labels={'avgMonthlyInfeedKWh':'Avg Monthly Net Infeed (kWh)'},\n",
    "    color_discrete_sequence=elhub_colors\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    texttemplate='%{text:,.0f}',\n",
    "    textposition='inside',\n",
    "    textfont=dict(color='white', size=BAR_TEXT_FS),\n",
    "    cliponaxis=False\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_font=dict(size=TITLE_FS, family=FONT_FAMILY),\n",
    "    title_x=0.5,\n",
    "    font=dict(family=FONT_FAMILY),\n",
    "    xaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    showlegend=False,\n",
    "    margin=dict(t=100, b=80),\n",
    "    plot_bgcolor='white',\n",
    "    paper_bgcolor='white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# 7) Export to PDF\n",
    "output_path = \"average_monthly_net_infeed_per_price_area.pdf\"\n",
    "fig.write_image(\n",
    "    output_path,\n",
    "    format=\"pdf\",\n",
    "    width=1000,\n",
    "    height=700,\n",
    "    scale=1\n",
    ")\n",
    "print(f\"âœ… Saved PDF to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef406d7",
   "metadata": {},
   "source": [
    "### Diurnal Profile of grid net infeed - sorted by price season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd88c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# â”€â”€â”€ FONT SIZE SETTINGS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "TITLE_FS      = 24\n",
    "AXIS_TITLE_FS = 20\n",
    "TICK_FS       = 18\n",
    "MARKER_SIZE   = 8\n",
    "FONT_FAMILY   = \"Roboto\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Elhub brand colors (weâ€™ll use the first four for the four seasons)\n",
    "season_colors = [\n",
    "    \"#212148\",  # winter (MÃ¸rk Lilla)\n",
    "    \"#7fb48a\",  # spring (GrÃ¸nn)\n",
    "    \"#5369b2\",  # summer (BlÃ¥)\n",
    "    \"#05677d\",  # autumn (BlÃ¥-grÃ¸nn)\n",
    "]\n",
    "\n",
    "# 1) Copy & localize timestamps\n",
    "df = big_df.copy()\n",
    "df['startTime'] = (\n",
    "    pd.to_datetime(df['startTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "\n",
    "# 2) Build dynamic title span\n",
    "span_start = df['startTime'].min().date().isoformat()\n",
    "span_end   = df['startTime'].max().date().isoformat()\n",
    "\n",
    "# 3) Extract month & hour\n",
    "df['month'] = df['startTime'].dt.month\n",
    "df['hour']  = df['startTime'].dt.hour\n",
    "\n",
    "# 4) Map month â†’ season\n",
    "season_map = {\n",
    "    **dict.fromkeys([12, 1, 2],   'winter'),\n",
    "    **dict.fromkeys([3, 4, 5],    'spring'),\n",
    "    **dict.fromkeys([6, 7, 8],    'summer'),\n",
    "    **dict.fromkeys([9, 10, 11],  'autumn'),\n",
    "}\n",
    "df['season'] = df['month'].map(season_map)\n",
    "\n",
    "# 5) Enforce season ordering\n",
    "season_cat = CategoricalDtype(['winter','spring','summer','autumn'], ordered=True)\n",
    "df['season'] = df['season'].astype(season_cat)\n",
    "\n",
    "# 6) Compute avg infeed per hour & season\n",
    "avg_season_hourly = (\n",
    "    df\n",
    "    .groupby(['season','hour'], observed=True)['netInfeedQuantityKwh']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'netInfeedQuantityKwh':'avgHourlyInfeedKWh'})\n",
    ")\n",
    "\n",
    "# 7) Compute each seasonâ€™s share of that hourâ€™s total\n",
    "hourly_totals = avg_season_hourly.groupby('hour')['avgHourlyInfeedKWh'].transform('sum')\n",
    "avg_season_hourly['pctOfHour'] = avg_season_hourly['avgHourlyInfeedKWh'] / hourly_totals\n",
    "\n",
    "# 8) Title text\n",
    "title_text = (\n",
    "    f\"Average Hourly Infeed by Season\\n\"\n",
    "    f\"({span_start} to {span_end})\"\n",
    ")\n",
    "\n",
    "# 9) Create the line chart, carrying season & pctOfHour in custom_data\n",
    "fig = px.line(\n",
    "    avg_season_hourly,\n",
    "    x='hour',\n",
    "    y='avgHourlyInfeedKWh',\n",
    "    color='season',\n",
    "    custom_data=['season','pctOfHour'],\n",
    "    markers=True,\n",
    "    title=title_text,\n",
    "    labels={\n",
    "        'hour': 'Hour of Day',\n",
    "        'avgHourlyInfeedKWh': 'Avg Hourly Infeed (kWh)',\n",
    "        'season': 'Season'\n",
    "    },\n",
    "    color_discrete_sequence=season_colors\n",
    ")\n",
    "\n",
    "# 10) Style traces & hovertemplate\n",
    "fig.update_traces(\n",
    "    marker=dict(size=MARKER_SIZE),\n",
    "    line=dict(width=3),\n",
    "    hovertemplate=(\n",
    "        \"%{y:,.0f} kWh<br>\"\n",
    "        \"Hour: %{x}<br>\"\n",
    "        \"Season: %{customdata[0]}<br>\"\n",
    "        \"Share: %{customdata[1]:.1%}\"\n",
    "        \"<extra></extra>\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 11) Layout styling\n",
    "fig.update_layout(\n",
    "    title_font=dict(size=TITLE_FS, family=FONT_FAMILY),\n",
    "    title_x=0.5,\n",
    "    font=dict(family=FONT_FAMILY),\n",
    "    xaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS),\n",
    "        dtick=1\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    legend_title_text='Season',\n",
    "    legend=dict(\n",
    "        title_font_size=AXIS_TITLE_FS,\n",
    "        font_size=TICK_FS,\n",
    "        orientation='h',\n",
    "        yanchor='bottom',\n",
    "        y=1.02,\n",
    "        xanchor='center',\n",
    "        x=0.5\n",
    "    ),\n",
    "    margin=dict(t=100, b=80),\n",
    "    plot_bgcolor='white',\n",
    "    paper_bgcolor='white'\n",
    ")\n",
    "\n",
    "# 12) Show & export\n",
    "fig.show()\n",
    "\n",
    "output_path = \"diurnal_profile_infeed_by_season.pdf\"\n",
    "fig.write_image(\n",
    "    output_path,\n",
    "    format=\"pdf\",\n",
    "    width=1000,\n",
    "    height=700,\n",
    "    scale=1\n",
    ")\n",
    "print(f\"âœ… Saved PDF to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa517693",
   "metadata": {},
   "source": [
    "### Diurnal Profile of grid net infeed - sorted by price area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526e9ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# â”€â”€â”€ ELHUB DESIGN MANUAL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "TITLE_FS        = 24        # Title font size\n",
    "AXIS_TITLE_FS   = 20        # Axis title font size\n",
    "TICK_FS         = 18        # Tick label font size\n",
    "MARKER_SIZE     = 8         # Marker diameter\n",
    "LINE_WIDTH      = 3         # Line width\n",
    "FONT_FAMILY     = \"Roboto\"  # Global font\n",
    "\n",
    "# Elhub palette for 5 price areas (from design manual):\n",
    "ELHUB_PALETTE = [\n",
    "    \"#212148\",  # MÃ¸rk Lilla\n",
    "    \"#7fb48a\",  # GrÃ¸nn\n",
    "    \"#5369b2\",  # BlÃ¥\n",
    "    \"#05677d\",  # BlÃ¥-grÃ¸nn\n",
    "    \"#886599\",  # Lilla\n",
    "    \"#d58000\",  # Oker\n",
    "]\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1) Copy & localize timestamps\n",
    "df = big_df.copy()\n",
    "df['startTime'] = (\n",
    "    pd.to_datetime(df['startTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "\n",
    "# 2) Build dynamic title span\n",
    "span_start = df['startTime'].min().date().isoformat()\n",
    "span_end   = df['startTime'].max().date().isoformat()\n",
    "\n",
    "# 3) Extract hour of day\n",
    "df['hour'] = df['startTime'].dt.hour\n",
    "\n",
    "# 4) Compute avg infeed per hour & price area\n",
    "avg_price_hourly = (\n",
    "    df\n",
    "    .groupby(['priceArea', 'hour'], observed=True)['netInfeedQuantityKwh']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'netInfeedQuantityKwh':'avgHourlyInfeedKWh'})\n",
    ")\n",
    "\n",
    "# 5) Compute each areaâ€™s share of that hourâ€™s total\n",
    "hourly_totals = avg_price_hourly.groupby('hour')['avgHourlyInfeedKWh'].transform('sum')\n",
    "avg_price_hourly['pctOfHour'] = avg_price_hourly['avgHourlyInfeedKWh'] / hourly_totals\n",
    "\n",
    "# 6) Title text\n",
    "title_text = (\n",
    "    f\"Average Hourly Infeed by Price Area\\n\"\n",
    "    f\"({span_start} to {span_end})\"\n",
    ")\n",
    "\n",
    "# 7) Create the line chart carrying priceArea & pctOfHour in custom_data\n",
    "fig = px.line(\n",
    "    avg_price_hourly,\n",
    "    x='hour',\n",
    "    y='avgHourlyInfeedKWh',\n",
    "    color='priceArea',\n",
    "    custom_data=['priceArea', 'pctOfHour'],\n",
    "    markers=True,\n",
    "    title=title_text,\n",
    "    labels={\n",
    "        'hour': 'Hour of Day',\n",
    "        'avgHourlyInfeedKWh': 'Avg Hourly Infeed (kWh)',\n",
    "        'priceArea': 'Price Area'\n",
    "    },\n",
    "    color_discrete_sequence=ELHUB_PALETTE\n",
    ")\n",
    "\n",
    "# 8) Apply Elhub styling touches and enhanced hovertemplate\n",
    "fig.update_traces(\n",
    "    marker=dict(size=MARKER_SIZE),\n",
    "    line=dict(width=LINE_WIDTH),\n",
    "    hovertemplate=(\n",
    "        \"%{y:,.0f} kWh<br>\"\n",
    "        \"Hour: %{x}<br>\"\n",
    "        \"Area: %{customdata[0]}<br>\"\n",
    "        \"Share: %{customdata[1]:.1%}\"\n",
    "        \"<extra></extra>\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 9) Layout styling\n",
    "fig.update_layout(\n",
    "    title_font=dict(size=TITLE_FS, family=FONT_FAMILY),\n",
    "    title_x=0.5,\n",
    "    font=dict(family=FONT_FAMILY),\n",
    "    xaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS),\n",
    "        dtick=1\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    legend_title_text='Price Area',\n",
    "    legend=dict(\n",
    "        title_font_size=AXIS_TITLE_FS,\n",
    "        font_size=TICK_FS,\n",
    "        orientation='h',\n",
    "        yanchor='bottom',\n",
    "        y=1.02,\n",
    "        xanchor='center',\n",
    "        x=0.5\n",
    "    ),\n",
    "    margin=dict(t=100, b=80),\n",
    "    plot_bgcolor='white',\n",
    "    paper_bgcolor='white'\n",
    ")\n",
    "\n",
    "# 10) Show & export\n",
    "fig.show()\n",
    "\n",
    "output_path = \"diurnal_profile_infeed_by_price_area.pdf\"\n",
    "fig.write_image(\n",
    "    output_path,\n",
    "    format=\"pdf\",\n",
    "    width=1000,\n",
    "    height=700,\n",
    "    scale=1\n",
    ")\n",
    "print(f\"âœ… Saved PDF to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18499281",
   "metadata": {},
   "source": [
    "### Daily Grid Loss by Price Area - every day - perhaps most useful in an interactive dashboard - streamlit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed06a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# â”€â”€â”€ ELHUB DESIGN MANUAL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "TITLE_FS      = 24        # Title font size\n",
    "AXIS_TITLE_FS = 20        # Axis title font size\n",
    "TICK_FS       = 18        # Tick label font size\n",
    "FONT_FAMILY   = \"Roboto\"  # Global font\n",
    "\n",
    "# ELhub palette for price areas\n",
    "ELHUB_PALETTE = [\n",
    "    \"#212148\",  # MÃ¸rk Lilla\n",
    "    \"#7fb48a\",  # GrÃ¸nn\n",
    "    \"#5369b2\",  # BlÃ¥\n",
    "    \"#05677d\",  # BlÃ¥-grÃ¸nn\n",
    "    \"#886599\",  # Lilla\n",
    "    \"#d58000\",  # Oker\n",
    "]\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1) Prepare your DataFrame (assumes big_df is loaded)\n",
    "df = big_df.copy()\n",
    "df['startTime'] = (\n",
    "    pd.to_datetime(df['startTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "\n",
    "# 2) Extract date span for title\n",
    "span_start = df['startTime'].min().date().isoformat()\n",
    "span_end   = df['startTime'].max().date().isoformat()\n",
    "\n",
    "# 3) Extract date (YYYY-MM-DD)\n",
    "df['date'] = df['startTime'].dt.date.astype(str)\n",
    "\n",
    "# 4) Aggregate total loss per day and priceArea\n",
    "daily_loss = (\n",
    "    df\n",
    "    .groupby(['date', 'priceArea'], observed=True)['calculatedLossQuantityKwh']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 5) Compute each areaâ€™s percentage of that dayâ€™s total\n",
    "totals = daily_loss.groupby('date')['calculatedLossQuantityKwh'].transform('sum')\n",
    "daily_loss['pctOfTotal'] = daily_loss['calculatedLossQuantityKwh'] / totals\n",
    "\n",
    "# 6) Build title\n",
    "title_text = (\n",
    "    f\"Daily Grid Loss by Price Area\\n\"\n",
    "    f\"({span_start} to {span_end})\"\n",
    ")\n",
    "\n",
    "# 7) Create the stacked bar chart, carrying pctOfTotal in custom_data\n",
    "fig = px.bar(\n",
    "    daily_loss,\n",
    "    x='date',\n",
    "    y='calculatedLossQuantityKwh',\n",
    "    color='priceArea',\n",
    "    custom_data=['priceArea', 'pctOfTotal'],   # embed both fields\n",
    "    title=title_text,\n",
    "    labels={\n",
    "        'date': 'Date',\n",
    "        'calculatedLossQuantityKwh': 'Total Loss (kWh)',\n",
    "        'priceArea': 'Price Area'\n",
    "    },\n",
    "    color_discrete_sequence=ELHUB_PALETTE,\n",
    "    opacity=1.0\n",
    ")\n",
    "\n",
    "# 8) ELhub styling on black background and enhanced hovertemplate\n",
    "fig.update_traces(\n",
    "    marker_line_width=0.5,\n",
    "    marker_line_color='white',\n",
    "    hovertemplate=(\n",
    "        \"%{y:,.0f} kWh<br>\"           # total loss\n",
    "        \"Date: %{x}<br>\"             # date\n",
    "        \"Area: %{customdata[0]}<br>\" # priceArea\n",
    "        \"Share: %{customdata[1]:.1%}\"# percentage of daily total\n",
    "        \"<extra></extra>\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    font=dict(family=FONT_FAMILY, color='white'),\n",
    "    title=dict(\n",
    "        text=title_text,\n",
    "        font=dict(size=TITLE_FS, family=FONT_FAMILY, color='white'),\n",
    "        x=0.5\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS, color='white'),\n",
    "        tickfont=dict(size=TICK_FS, color='white'),\n",
    "        type='category',\n",
    "        categoryorder='category ascending',\n",
    "        gridcolor='#222222'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS, color='white'),\n",
    "        tickfont=dict(size=TICK_FS, color='white'),\n",
    "        gridcolor='#222222'\n",
    "    ),\n",
    "    legend_title_text='Price Area',\n",
    "    legend=dict(\n",
    "        title_font_size=AXIS_TITLE_FS,\n",
    "        font_size=TICK_FS,\n",
    "        font_color='white',\n",
    "        orientation='h',\n",
    "        yanchor='bottom',\n",
    "        y=1.02,\n",
    "        xanchor='center',\n",
    "        x=0.5,\n",
    "        bgcolor='rgba(0,0,0,0)'\n",
    "    ),\n",
    "    plot_bgcolor='black',\n",
    "    paper_bgcolor='black',\n",
    "    margin=dict(t=100, b=80),\n",
    "    barmode='stack'\n",
    ")\n",
    "\n",
    "# 9) Show and export\n",
    "fig.show()\n",
    "\n",
    "output_path = \"daily_all_grid_loss_by_price_area.pdf\"\n",
    "fig.write_image(\n",
    "    output_path,\n",
    "    format=\"pdf\",\n",
    "    width=1000,\n",
    "    height=700,\n",
    "    scale=1\n",
    ")\n",
    "print(f\"âœ… Saved PDF to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46d3ddb",
   "metadata": {},
   "source": [
    "### Monthly Grid Loss by Price Area every month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72500970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# â”€â”€â”€ FONT SIZE & FAMILY SETTINGS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "TITLE_FS        = 24   # plot title\n",
    "AXIS_TITLE_FS   = 20   # x/y axis titles\n",
    "TICK_FS         = 18   # x/y tick labels\n",
    "LEGEND_TITLE_FS = 18   # legend title\n",
    "LEGEND_FS       = 16   # legend items\n",
    "FONT_FAMILY     = \"Roboto\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Elhub brand colors\n",
    "elhub_colors = [\n",
    "    \"#212148\",  # MÃ¸rk Lilla\n",
    "    \"#7fb48a\",  # GrÃ¸nn\n",
    "    \"#5369b2\",  # BlÃ¥\n",
    "    \"#05677d\",  # BlÃ¥-grÃ¸nn\n",
    "    \"#886599\",  # Lilla\n",
    "    \"#d58000\",  # Oker\n",
    "]\n",
    "\n",
    "# 1) Parse startTime as UTC then convert to Oslo\n",
    "df = big_df.copy()\n",
    "df['startTime'] = (\n",
    "    pd.to_datetime(df['startTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "\n",
    "# 2) Determine span for title (first to last month)\n",
    "span_start = df['startTime'].dt.to_period('M').min().to_timestamp().strftime('%Y-%m')\n",
    "span_end   = df['startTime'].dt.to_period('M').max().to_timestamp().strftime('%Y-%m')\n",
    "\n",
    "# 3) Extract month period\n",
    "df['month'] = df['startTime'].dt.to_period('M').astype(str)\n",
    "\n",
    "# 4) Aggregate total loss per month and priceArea\n",
    "monthly_loss = (\n",
    "    df\n",
    "    .groupby(['month', 'priceArea'])['calculatedLossQuantityKwh']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 5) Compute each priceArea's percentage share of that month's total loss\n",
    "monthly_loss['month_total'] = monthly_loss.groupby('month')['calculatedLossQuantityKwh'].transform('sum')\n",
    "monthly_loss['pctShare']    = monthly_loss['calculatedLossQuantityKwh'] / monthly_loss['month_total'] * 100\n",
    "\n",
    "# 6) Build dynamic title\n",
    "title_text = (\n",
    "    f\"Monthly Grid Loss by Price Area (stacked)\\n\"\n",
    "    f\"({span_start} to {span_end})\"\n",
    ")\n",
    "\n",
    "# 7) Create the stacked bar chart with Elhub colours,\n",
    "#    and carry pctShare through custom_data for the hover only\n",
    "fig = px.bar(\n",
    "    monthly_loss,\n",
    "    x='month',\n",
    "    y='calculatedLossQuantityKwh',\n",
    "    color='priceArea',\n",
    "    custom_data=['pctShare'],\n",
    "    title=title_text,\n",
    "    labels={\n",
    "        'month': 'Month',\n",
    "        'calculatedLossQuantityKwh': 'Total Loss (kWh)',\n",
    "        'priceArea': 'Price Area'\n",
    "    },\n",
    "    category_orders={'month': sorted(monthly_loss['month'].unique())},\n",
    "    color_discrete_sequence=elhub_colors\n",
    ")\n",
    "\n",
    "# 8) Stack bars and style, but remove any insideâ€bar text\n",
    "fig.update_layout(\n",
    "    barmode='stack',\n",
    "    title_font=dict(size=TITLE_FS, family=FONT_FAMILY),\n",
    "    title_x=0.5,\n",
    "    font=dict(family=FONT_FAMILY),\n",
    "    xaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS),\n",
    "        categoryorder='category ascending'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    legend_title_font=dict(size=LEGEND_TITLE_FS),\n",
    "    legend_font=dict(size=LEGEND_FS),\n",
    "    margin=dict(t=100, b=80),\n",
    "    plot_bgcolor='white',\n",
    "    paper_bgcolor='white'\n",
    ")\n",
    "\n",
    "# 9) Add hovertemplate so only the tooltip shows the kWh and % share\n",
    "fig.update_traces(\n",
    "    text=None,\n",
    "    hovertemplate=(\n",
    "        \"<b>Price Area:</b> %{fullData.name}<br>\"\n",
    "        \"<b>Month:</b> %{x}<br>\"\n",
    "        \"<b>Total Loss:</b> %{y:,.0f} kWh<br>\"\n",
    "        \"<b>Share:</b> %{customdata[0]:.1f}%<extra></extra>\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 10) Render\n",
    "fig.show()\n",
    "\n",
    "# 11) Export to PDF\n",
    "output_path = \"monthly_grid_loss_per_price_area.pdf\"\n",
    "fig.write_image(\n",
    "    output_path,\n",
    "    format=\"pdf\",\n",
    "    width=1000,\n",
    "    height=700,\n",
    "    scale=1\n",
    ")\n",
    "print(f\"âœ… Saved PDF to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02548e6",
   "metadata": {},
   "source": [
    "### Monthly Grid Loss by Price Area aggregated by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d089647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# â”€â”€â”€ FONT SIZE & FAMILY SETTINGS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "TITLE_FS        = 24   # plot title\n",
    "AXIS_TITLE_FS   = 20   # x/y axis titles\n",
    "TICK_FS         = 18   # x/y tick labels\n",
    "LEGEND_TITLE_FS = 18   # legend title\n",
    "LEGEND_FS       = 16   # legend items\n",
    "FONT_FAMILY     = \"Roboto\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Elhub brand colors\n",
    "elhub_colors = [\n",
    "    \"#212148\",  # MÃ¸rk Lilla\n",
    "    \"#7fb48a\",  # GrÃ¸nn\n",
    "    \"#5369b2\",  # BlÃ¥\n",
    "    \"#05677d\",  # BlÃ¥-grÃ¸nn\n",
    "    \"#886599\",  # Lilla\n",
    "    \"#d58000\",  # Oker\n",
    "]\n",
    "\n",
    "# â”€â”€â”€ PREPARE YOUR DATAFRAME â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df = big_df.copy()\n",
    "df['startTime'] = (\n",
    "    pd.to_datetime(df['startTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "df['year']        = df['startTime'].dt.year\n",
    "df['month_num']   = df['startTime'].dt.month\n",
    "df['month_name']  = df['startTime'].dt.month_name().str.slice(stop=3)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1) Compute monthly total loss for each yearâ€month & priceArea\n",
    "monthly_totals = (\n",
    "    df\n",
    "    .groupby(['year','month_num','month_name','priceArea'])['calculatedLossQuantityKwh']\n",
    "    .sum()\n",
    "    .reset_index(name='monthlyLossKWh')\n",
    ")\n",
    "\n",
    "# 2) Average across years to get one value per calendar month & priceArea\n",
    "avg_calendar = (\n",
    "    monthly_totals\n",
    "    .groupby(['month_num','month_name','priceArea'])['monthlyLossKWh']\n",
    "    .mean()\n",
    "    .reset_index(name='avgMonthlyLossKWh')\n",
    ")\n",
    "\n",
    "# 3) Ensure calendarâ€month ordering Jan â†’ Dec\n",
    "month_order = [\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]\n",
    "avg_calendar['month_name'] = pd.Categorical(\n",
    "    avg_calendar['month_name'],\n",
    "    categories=month_order,\n",
    "    ordered=True\n",
    ")\n",
    "avg_calendar = avg_calendar.sort_values('month_name')\n",
    "\n",
    "# 4) Compute each priceArea's percentage share of that calendarâ€month avg loss\n",
    "avg_calendar['month_total'] = avg_calendar.groupby('month_name')['avgMonthlyLossKWh'].transform('sum')\n",
    "avg_calendar['pctShare']    = avg_calendar['avgMonthlyLossKWh'] / avg_calendar['month_total'] * 100\n",
    "\n",
    "# 5) Build dynamic title\n",
    "year_start = df['year'].min()\n",
    "year_end   = df['year'].max()\n",
    "title_text = (\n",
    "    f\"Average Monthly Grid Loss by Price Area\\n\"\n",
    "    f\"(Calendar Months {year_start}â€“{year_end})\"\n",
    ")\n",
    "\n",
    "# 6) Create the stacked bar chart with Elhub colours,\n",
    "#    carry pctShare into custom_data for the hover only\n",
    "fig = px.bar(\n",
    "    avg_calendar,\n",
    "    x='month_name',\n",
    "    y='avgMonthlyLossKWh',\n",
    "    color='priceArea',\n",
    "    custom_data=['pctShare'],\n",
    "    title=title_text,\n",
    "    labels={\n",
    "        'month_name': 'Month',\n",
    "        'avgMonthlyLossKWh': 'Avg Loss (kWh)',\n",
    "        'priceArea': 'Price Area'\n",
    "    },\n",
    "    category_orders={'month_name': month_order},\n",
    "    color_discrete_sequence=elhub_colors\n",
    ")\n",
    "\n",
    "# 7) Style the layout\n",
    "fig.update_layout(\n",
    "    barmode='stack',\n",
    "    title_font=dict(size=TITLE_FS, family=FONT_FAMILY),\n",
    "    title_x=0.5,\n",
    "    font=dict(family=FONT_FAMILY),\n",
    "    xaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS),\n",
    "        categoryorder='array',\n",
    "        categoryarray=month_order\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_font=dict(size=AXIS_TITLE_FS),\n",
    "        tickfont=dict(size=TICK_FS)\n",
    "    ),\n",
    "    legend_title_font=dict(size=LEGEND_TITLE_FS),\n",
    "    legend_font=dict(size=LEGEND_FS),\n",
    "    margin=dict(t=100, b=80),\n",
    "    plot_bgcolor='white',\n",
    "    paper_bgcolor='white'\n",
    ")\n",
    "\n",
    "# 8) Add hovertemplate so only the tooltip shows kWh + % share\n",
    "fig.update_traces(\n",
    "    hovertemplate=(\n",
    "        \"<b>Price Area:</b> %{fullData.name}<br>\"\n",
    "        \"<b>Month:</b> %{x}<br>\"\n",
    "        \"<b>Avg Loss:</b> %{y:,.0f} kWh<br>\"\n",
    "        \"<b>Share:</b> %{customdata[0]:.1f}%<extra></extra>\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 9) Render\n",
    "fig.show()\n",
    "\n",
    "# 10) Export to PDF\n",
    "output_path = \"average_monthly_grid_loss_by_price_area_calendar.pdf\"\n",
    "fig.write_image(\n",
    "    output_path,\n",
    "    format=\"pdf\",\n",
    "    width=1000,\n",
    "    height=700,\n",
    "    scale=1\n",
    ")\n",
    "print(f\"âœ… Saved PDF to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609aa5b2",
   "metadata": {},
   "source": [
    "### Histogram of Hourly Losses by Price Area and season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b10415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# â”€â”€â”€ FONT SIZE & FAMILY SETTINGS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "TITLE_FS           = 24   # plot title\n",
    "AXIS_TITLE_FS      = 22   # x/y axis titles\n",
    "TICK_FS            = 20   # x/y tick labels\n",
    "SUBPLOT_TITLE_FS   = 20   # subplot titles (season & price area)\n",
    "FONT_FAMILY        = \"Roboto\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Elhub brand colors\n",
    "elhub_colors = [\n",
    "    \"#212148\",  # MÃ¸rk Lilla\n",
    "    \"#7fb48a\",  # GrÃ¸nn\n",
    "    \"#5369b2\",  # BlÃ¥\n",
    "    \"#05677d\",  # BlÃ¥-grÃ¸nn\n",
    "    \"#886599\",  # Lilla\n",
    "    \"#d58000\",  # Oker\n",
    "]\n",
    "season_colors = {\n",
    "    'Summer': elhub_colors[0],\n",
    "    'Winter': elhub_colors[1],\n",
    "}\n",
    "\n",
    "# â”€â”€ Assumes big_df exists with columns: 'startTime','priceArea','calculatedLossQuantityKwh' â”€â”€\n",
    "\n",
    "# 1) Localize timestamps & extract month/season\n",
    "df = big_df.copy()\n",
    "df['startTime'] = (\n",
    "    pd.to_datetime(df['startTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "df['month'] = df['startTime'].dt.month\n",
    "df['season'] = df['month'].map(\n",
    "    lambda m: 'Summer' if m in (6,7,8)\n",
    "              else 'Winter' if m in (12,1,2)\n",
    "              else None\n",
    ")\n",
    "df = df[df['season'].notna()]\n",
    "\n",
    "# 2) Only include strictly positive loss values\n",
    "df = df[df['calculatedLossQuantityKwh'] > 0]\n",
    "\n",
    "# 3) Compute overall span for title (month/year only)\n",
    "span_start = df['startTime'].min().strftime('%b %Y')\n",
    "span_end   = df['startTime'].max().strftime('%b %Y')\n",
    "\n",
    "# 4) Determine 0th and 90th percentiles for trimming\n",
    "lo, hi = df['calculatedLossQuantityKwh'].quantile([0.0, 0.9])\n",
    "\n",
    "# 5) Prepare subplots with unique titles per cell\n",
    "price_areas = sorted(df['priceArea'].unique())\n",
    "n = len(price_areas)\n",
    "subplot_titles = []\n",
    "for pa in price_areas:\n",
    "    subplot_titles += [\n",
    "        f\"{pa} â€” Summer\",\n",
    "        f\"{pa} â€” Winter\"\n",
    "    ]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=n, cols=2,\n",
    "    shared_xaxes='rows',\n",
    "    horizontal_spacing=0.1,   # increased gap between columns\n",
    "    vertical_spacing=0.08,\n",
    "    subplot_titles=subplot_titles\n",
    ")\n",
    "\n",
    "# 6) Bins\n",
    "bins = np.linspace(lo, hi, 40)\n",
    "\n",
    "# 7) Add histograms with Elhub colors\n",
    "for i, pa in enumerate(price_areas, start=1):\n",
    "    for j, season in enumerate(['Summer', 'Winter'], start=1):\n",
    "        data = (\n",
    "            df[(df['priceArea']==pa) & (df['season']==season)]\n",
    "              ['calculatedLossQuantityKwh']\n",
    "              .clip(lo, hi)\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=data,\n",
    "                xbins=dict(start=lo, end=hi, size=(hi-lo)/40),\n",
    "                marker_color=season_colors[season],\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=i, col=j\n",
    "        )\n",
    "\n",
    "# 8) Uniform x-axis range, tick labels, more ticks, angled labels, and automargin\n",
    "for i in range(1, n+1):\n",
    "    for j in (1, 2):\n",
    "        fig.update_xaxes(\n",
    "            range=[lo, hi],\n",
    "            showticklabels=True,\n",
    "            nticks=8,\n",
    "            tickangle=0,\n",
    "            automargin=True,\n",
    "            row=i, col=j\n",
    "        )\n",
    "\n",
    "# 9) Label bottom row x-axes\n",
    "x_title = \"Loss (kWh) trimmed to 0â€“90 percentile\"\n",
    "fig.update_xaxes(title_text=x_title, row=n, col=1)\n",
    "fig.update_xaxes(title_text=x_title, row=n, col=2)\n",
    "\n",
    "# 10) Y-axis labels: only on Summer column, with automargin\n",
    "for i in range(1, n+1):\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"Frequency\",\n",
    "        automargin=True,\n",
    "        row=i, col=1\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"\",\n",
    "        row=i, col=2\n",
    "    )\n",
    "\n",
    "# 11) Apply Elhub styling and dynamic sizing\n",
    "fig.update_layout(\n",
    "    title_text=(\n",
    "        f\"Seasonal Distributions of Hourly Loss by Price Area (0â€“90% trimmed)<br>\"\n",
    "        f\"{span_start} â€“ {span_end}\"\n",
    "    ),\n",
    "    title_x=0.5,\n",
    "    title_font=dict(size=TITLE_FS, family=FONT_FAMILY),\n",
    "    font=dict(family=FONT_FAMILY),\n",
    "    plot_bgcolor='white',\n",
    "    paper_bgcolor='white',\n",
    "    margin=dict(\n",
    "        t=140,   # top for title\n",
    "        b=120,   # bottom for x-ticks\n",
    "        l=100    # left for y-ticks\n",
    "    ),\n",
    "    height=300 * n,\n",
    "    width=900,   # slight width bump to accommodate wider gap\n",
    "    autosize=True\n",
    ")\n",
    "\n",
    "# 12) Axis fonts\n",
    "fig.update_xaxes(\n",
    "    title_font=dict(size=AXIS_TITLE_FS, family=FONT_FAMILY),\n",
    "    tickfont=dict(size=TICK_FS)\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    title_font=dict(size=AXIS_TITLE_FS, family=FONT_FAMILY),\n",
    "    tickfont=dict(size=TICK_FS)\n",
    ")\n",
    "\n",
    "# 13) Subplot title fonts\n",
    "for ann in fig.layout.annotations:\n",
    "    ann.font = dict(size=SUBPLOT_TITLE_FS, family=FONT_FAMILY)\n",
    "\n",
    "# 14) Show and save\n",
    "fig.show()\n",
    "\n",
    "output_path = \"histogram_seasonal_hourly_loss_by_price_area.pdf\"\n",
    "fig.write_image(\n",
    "    output_path,\n",
    "    format=\"pdf\",\n",
    "    width=900,\n",
    "    height=300 * n,\n",
    "    scale=1\n",
    ")\n",
    "print(f\"âœ… Saved PDF to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5043fa40",
   "metadata": {},
   "source": [
    "### Histogram of Summer/Winter hourly loss distributions for the lowest, median and highestâ€infeed gridâ€areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a87b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# â”€â”€â”€ FONT SIZE & FAMILY SETTINGS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "TITLE_FS           = 24   # plot title\n",
    "AXIS_TITLE_FS      = 22   # x/y axis titles\n",
    "TICK_FS            = 20   # x/y tick labels\n",
    "SUBPLOT_TITLE_FS   = 20   # subplot titles (gridâ€area & price area)\n",
    "FONT_FAMILY        = \"Roboto\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Elhub brand colors\n",
    "elhub_colors = [\n",
    "    \"#212148\",  # MÃ¸rk Lilla\n",
    "    \"#7fb48a\",  # GrÃ¸nn\n",
    "    \"#5369b2\",  # BlÃ¥\n",
    "    \"#05677d\",  # BlÃ¥â€grÃ¸nn\n",
    "    \"#886599\",  # Lilla\n",
    "    \"#d58000\",  # Oker\n",
    "]\n",
    "season_colors = {\n",
    "    'Summer': elhub_colors[0],\n",
    "    'Winter': elhub_colors[1],\n",
    "}\n",
    "\n",
    "# â”€â”€ Assumes big_df exists with columns:\n",
    "#    'startTime','gridArea','priceArea','calculatedLossQuantityKwh','netInfeedQuantityKwh'\n",
    "# â”€â”€\n",
    "\n",
    "# 1) Localize timestamps & extract month/season\n",
    "df = big_df.copy()\n",
    "df['startTime'] = (\n",
    "    pd.to_datetime(df['startTime'], utc=True)\n",
    "      .dt.tz_convert('Europe/Oslo')\n",
    ")\n",
    "df['month'] = df['startTime'].dt.month\n",
    "df['season'] = df['month'].map(\n",
    "    lambda m: 'Summer' if m in (6,7,8)\n",
    "              else 'Winter' if m in (12,1,2)\n",
    "              else None\n",
    ")\n",
    "# keep a full copy for netâ€infeed sums (all months)\n",
    "df_full = df.copy()\n",
    "# filter to just Summer/Winter for histograms\n",
    "df = df[df['season'].notna()]\n",
    "\n",
    "# 2) Optionally drop nonâ€positive losses (commented out so you see all values)\n",
    "# df = df[df['calculatedLossQuantityKwh'] > 0]\n",
    "\n",
    "# 3) Compute overall span for title (month/year only)\n",
    "span_start = df['startTime'].min().strftime('%b %Y')\n",
    "span_end   = df['startTime'].max().strftime('%b %Y')\n",
    "\n",
    "# â”€â”€ Determine gridâ€areas by netInfeedQuantityKwh total â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "totals = (\n",
    "    df_full\n",
    "      .groupby('gridArea', as_index=False)['netInfeedQuantityKwh']\n",
    "      .sum()\n",
    "      .sort_values('netInfeedQuantityKwh')\n",
    ")\n",
    "lowest  = totals.iloc[0,   0]\n",
    "highest = totals.iloc[-1,  0]\n",
    "median  = totals.iloc[len(totals)//2, 0]\n",
    "selected_grid_areas = [lowest, median, highest]\n",
    "\n",
    "# Map each to its priceArea (first occurrence)\n",
    "price_map = (\n",
    "    df_full\n",
    "      .drop_duplicates(['gridArea'])\n",
    "      .set_index('gridArea')['priceArea']\n",
    "      .to_dict()\n",
    ")\n",
    "\n",
    "# 4) Compute 0â€“90th percentiles for trimming\n",
    "lo, hi = df['calculatedLossQuantityKwh'].quantile([0.0, 0.9])\n",
    "\n",
    "# 5) Build subplot titles with row labels\n",
    "row_labels = ['Lowest', 'Median', 'Highest']\n",
    "subplot_titles = []\n",
    "for idx, ga in enumerate(selected_grid_areas):\n",
    "    pa    = price_map.get(ga, \"Unknown\")\n",
    "    label = row_labels[idx]\n",
    "    subplot_titles += [\n",
    "        f\"[{label}] {ga} ({pa}) â€” Summer\",\n",
    "        f\"[{label}] {ga} ({pa}) â€” Winter\"\n",
    "    ]\n",
    "\n",
    "# 6) Create 3Ã—2 subplot grid\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    shared_xaxes='rows',\n",
    "    horizontal_spacing=0.1,\n",
    "    vertical_spacing=0.08,\n",
    "    subplot_titles=subplot_titles\n",
    ")\n",
    "\n",
    "# 7) Bins\n",
    "bins = np.linspace(lo, hi, 40)\n",
    "\n",
    "# 8) Add histograms\n",
    "for i, ga in enumerate(selected_grid_areas, start=1):\n",
    "    for j, season in enumerate(['Summer', 'Winter'], start=1):\n",
    "        vals = (\n",
    "            df[(df['gridArea']==ga) & (df['season']==season)]\n",
    "              ['calculatedLossQuantityKwh']\n",
    "              .clip(lo, hi)\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=vals,\n",
    "                xbins=dict(start=lo, end=hi, size=(hi - lo) / 40),\n",
    "                marker_color=season_colors[season],\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=i, col=j\n",
    "        )\n",
    "\n",
    "# 9) Uniform axes, labels\n",
    "for i in range(1, 4):\n",
    "    for j in (1,2):\n",
    "        fig.update_xaxes(\n",
    "            range=[lo, hi],\n",
    "            nticks=8,\n",
    "            tickangle=0,\n",
    "            automargin=True,\n",
    "            row=i, col=j\n",
    "        )\n",
    "# bottomâ€row xâ€axis titles\n",
    "x_title = \"Loss (kWh) trimmed to 0â€“90 percentile\"\n",
    "fig.update_xaxes(title_text=x_title, row=3, col=1)\n",
    "fig.update_xaxes(title_text=x_title, row=3, col=2)\n",
    "\n",
    "# yâ€axes\n",
    "for i in range(1, 4):\n",
    "    fig.update_yaxes(title_text=\"Frequency\", automargin=True, row=i, col=1)\n",
    "    fig.update_yaxes(title_text=\"\", row=i, col=2)\n",
    "\n",
    "# 10) Layout & styling\n",
    "fig.update_layout(\n",
    "    title_text=(\n",
    "        f\"Seasonal Distributions of Hourly Loss by Selected Gridâ€Areas (0â€“90% trimmed)<br>\"\n",
    "        f\"{span_start} â€“ {span_end}\"\n",
    "    ),\n",
    "    title_x=0.5,\n",
    "    title_font=dict(size=TITLE_FS, family=FONT_FAMILY),\n",
    "    font=dict(family=FONT_FAMILY),\n",
    "    plot_bgcolor='white',\n",
    "    paper_bgcolor='white',\n",
    "    margin=dict(t=140, b=120, l=100),\n",
    "    height=300 * 3,\n",
    "    width=900,\n",
    "    autosize=True\n",
    ")\n",
    "fig.update_xaxes(title_font=dict(size=AXIS_TITLE_FS, family=FONT_FAMILY),\n",
    "                 tickfont=dict(size=TICK_FS))\n",
    "fig.update_yaxes(title_font=dict(size=AXIS_TITLE_FS, family=FONT_FAMILY),\n",
    "                 tickfont=dict(size=TICK_FS))\n",
    "for ann in fig.layout.annotations:\n",
    "    ann.font = dict(size=SUBPLOT_TITLE_FS, family=FONT_FAMILY)\n",
    "\n",
    "# 11) Show & save\n",
    "fig.show()\n",
    "output_path = \"histogram_seasonal_hourly_loss_by_gridArea.pdf\"\n",
    "fig.write_image(output_path, format=\"pdf\", width=900, height=300 * 3, scale=1)\n",
    "print(f\"âœ… Saved PDF to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e9a52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ RANGE SUMMARY FOR SELECTED GRID-AREAS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Assumes youâ€™ve already defined `df_full` and `selected_grid_areas`\n",
    "\n",
    "summary = (\n",
    "    df_full[df_full['gridArea'].isin(selected_grid_areas)]\n",
    "      .groupby('gridArea')\n",
    "      .agg(\n",
    "          netinfeed_min = ('netInfeedQuantityKwh', 'min'),\n",
    "          netinfeed_max = ('netInfeedQuantityKwh', 'max'),\n",
    "          loss_min      = ('calculatedLossQuantityKwh', 'min'),\n",
    "          loss_max      = ('calculatedLossQuantityKwh', 'max'),\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "print(\"\\nRange of netInfeedQuantityKwh & calculatedLossQuantityKwh for selected grid-areas:\\n\")\n",
    "print(summary.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db10a8",
   "metadata": {},
   "source": [
    "## Appendix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de819373",
   "metadata": {},
   "source": [
    "### Elhub color palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014d36e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "elhubs_palette = {\n",
    "    \"grey\": [\n",
    "        \"#2A2B2D\",  # Grey-900\n",
    "        \"#4D4F54\",  # Grey-800\n",
    "        \"#76777E\",  # Grey-700\n",
    "        \"#B4B4B9\",  # Grey-600\n",
    "        \"#CFD0D3\",  # Grey-500\n",
    "        \"#D8D8DC\",  # Grey-400\n",
    "        \"#F4F4F4\",  # Grey-300\n",
    "        \"#F6F6F6\",  # Grey-200\n",
    "        \"#FCFCFD\",  # Grey-100\n",
    "        \"#FFFFFF\",  # Grey-0\n",
    "    ],\n",
    "    \"green\": [\n",
    "        \"#0B3C28\",  # Green-700\n",
    "        \"#0A4420\",  # Green-600\n",
    "        \"#274E3B\",  # Green-550\n",
    "        \"#0F5537\",  # Green-500\n",
    "        \"#1F8F5D\",  # Green-450\n",
    "        \"#93E08A\",  # Green-400\n",
    "        \"#5FEF55\",  # Green-300\n",
    "        \"#F5FFF5\",  # Green-200\n",
    "        \"#E6F3EF\",  # Green-150\n",
    "    ],\n",
    "    \"blue\": [\n",
    "        \"#104AA2\",  # Blue-600\n",
    "        \"#4A60F2\",  # Blue-500\n",
    "        \"#E6F5FF\",  # Blue-400\n",
    "    ],\n",
    "    \"purple\": [\n",
    "        \"#27148B\",  # Purple-700\n",
    "        \"#3A2A7D\",  # Purple-600\n",
    "        \"#5F3DFF\",  # Purple-500\n",
    "        \"#ACB2FF\",  # Purple-400\n",
    "        \"#E3D7FF\",  # Purple-300\n",
    "        \"#F8F5FF\",  # Purple-200\n",
    "    ],\n",
    "    \"red\": [\n",
    "        \"#7F1D35\",  # Red-600\n",
    "        \"#D34A3D\",  # Red-500\n",
    "        \"#FCD2D2\",  # Red-400\n",
    "    ],\n",
    "    \"orange\": [\n",
    "        \"#F7430C\",  # Orange-700\n",
    "        \"#FFD070\",  # Orange-500\n",
    "        \"#FFE3C0\",  # Orange-300\n",
    "    ],\n",
    "    \"yellow\": [\n",
    "        \"#EEC116\",  # Yellow-500\n",
    "        \"#FFF8DF\",  # Yellow-400\n",
    "    ],\n",
    "    \"brown\": [\n",
    "        \"#77470D\",  # Brown-600\n",
    "    ],\n",
    "    \"beige\": [\n",
    "        \"#F0E6E5\",  # Beige-600\n",
    "        \"#FCFAF6\",  # Beige-400\n",
    "    ],\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gridloss_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
